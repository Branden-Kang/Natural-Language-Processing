{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbuMNye+AeFou4atRAGGIi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://levelup.gitconnected.com/how-i-created-the-most-powerful-nlp-library-in-python-c26d08a55809)"
      ],
      "metadata": {
        "id": "54EDicDSTCZ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the Library"
      ],
      "metadata": {
        "id": "mSNUxIx3TqPK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQLyqWbHTAfr",
        "outputId": "6bdcc4ec-bf2a-4373-87fa-4c598c9b9f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Most-powerful-NLP-library'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 24 (delta 12), reused 13 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (24/24), 22.05 KiB | 3.67 MiB/s, done.\n",
            "Resolving deltas: 100% (12/12), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/FareedKhan-dev/Most-powerful-NLP-library.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Google Generative AI library\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fowwPpC_TQpK",
        "outputId": "f1d4fb21-762f-4368-93e6-e0e01d7683b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/146.9 kB\u001b[0m \u001b[31m917.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/146.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.9/146.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Most-powerful-NLP-library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ipwf5h2rUS_K",
        "outputId": "45b7357f-be9b-4f35-b98a-d3cf7394fd1d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Most-powerful-NLP-library\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHhiJASyUXa-",
        "outputId": "9573a775-7035-41bc-b105-a062f89d8a22"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code.ipynb  core_nlp.py  for_beginners\tpre_processing.py  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initiating the Library"
      ],
      "metadata": {
        "id": "w02545OSTo_6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Google Generative AI library\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = \"Your-API-key\"\n",
        "\n",
        "# Configure the library with your API key\n",
        "genai.configure(api_key = os.environ['GOOGLE_API_KEY'])\n",
        "\n",
        "# Initialize the GenerativeModel with 'gemini-pro'\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "po7grye0TWp_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the Text"
      ],
      "metadata": {
        "id": "tk9SZBUdTsNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the clean_text function from the pre_processing module\n",
        "from pre_processing import clean_text\n",
        "\n",
        "# User input text\n",
        "user_input = '''faree$$@$%d khan will arrive at 9:00 AM.\n",
        "                He will@%$ 1meet you at the airport.'''\n",
        "\n",
        "# Clean the text using the specified model\n",
        "cleaned_text = clean_text(user_input, model)\n",
        "\n",
        "# Print the cleaned text\n",
        "print(cleaned_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "YE6e3thVTnuI",
        "outputId": "92b921c7-7816-465b-d4ee-f88d712c930e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fared Khan will arrive at 9:00 AM.\n",
            "He will meet you at the airport.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform Lemmatization or Stemming"
      ],
      "metadata": {
        "id": "ODS0cBJiYfPe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the lemmatize_text and stem_text functions from the pre_processing module\n",
        "from pre_processing import lemmatize_text, stem_text\n",
        "\n",
        "# User input text\n",
        "user_input = '''The cats are running and playing in the gardens,\n",
        "                while the dogs are barking loudly and chasing their tails'''\n",
        "\n",
        "# Lemmatize the text using the specified model\n",
        "lemmatized_sentence = lemmatize_text(user_input, model)\n",
        "\n",
        "# Stem the text using the specified model\n",
        "stemmed_sentence = stem_text(user_input, model)\n",
        "\n",
        "# Print the lemmatized and stemmed sentences\n",
        "print(lemmatized_sentence)\n",
        "print(stemmed_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "9p1a3ET9URSp",
        "outputId": "60e3b81a-ca44-40a1-939d-24622b85ff67"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat be run and play in the garden, while the dog be bark loud and chase their tail\n",
            "Cat run play garden dog bark loud chase tail\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simplifying NER Detection and POS Tagging"
      ],
      "metadata": {
        "id": "XI2xKk-sYiXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the detect_ner function from the core_nlp module\n",
        "from core_nlp import detect_ner\n",
        "\n",
        "# User input text\n",
        "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
        "\n",
        "# Specify NER tags (optional, default includes 'person, location, date, number, ...')\n",
        "ner_tags = 'person, location, date, number, ... cardinal'\n",
        "\n",
        "# Detect named entities in the text using the specified model and NER tags\n",
        "ner_result = detect_ner(input_text=user_input, ner_tags=ner_tags, model=model)\n",
        "\n",
        "# Print the NER result\n",
        "print(ner_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "sWlV3sxiYggw",
        "outputId": "45c53698-ad12-488a-bb16-3427a1906182"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "airport: location\n",
            "12:00 AM: time\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the detect_pos function from the core_nlp module\n",
        "from core_nlp import detect_pos\n",
        "\n",
        "# User input text\n",
        "user_input = \"I will meet you at the airport sharp 12:00 AM.\"\n",
        "\n",
        "# Specify POS tags (optional, default includes 'NOUN, verb, adjective, adverb, ...')\n",
        "pos_tags = 'noun, verb, adjective, adverb, pronoun, ... entity_phrase'\n",
        "\n",
        "# Detect part-of-speech in the text using the specified model and POS tags\n",
        "pos_result = detect_pos(input_text=user_input, pos_tags=pos_tags, model=model)\n",
        "\n",
        "# Print the POS result\n",
        "print(pos_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "HmStaVE5Yja_",
        "outputId": "a7abc07c-9058-492b-e7bc-38e2f9ea1a5e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I: pronoun\n",
            "will: verb\n",
            "meet: verb\n",
            "you: pronoun\n",
            "at: preposition\n",
            "the: determiner\n",
            "airport: noun\n",
            "sharp: adjective\n",
            "12:00: time\n",
            "AM: time\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Pattern Matching\n"
      ],
      "metadata": {
        "id": "CdcZyRaZYov6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the extract_patterns function from the pre_processing module\n",
        "from pre_processing import extract_patterns\n",
        "\n",
        "# User input text\n",
        "user_input = '''The phone number of fareed khan is 123-456-7890 and 523-456-7892. Please call for assistance and email me at x123@gmail.com'''\n",
        "\n",
        "# Define patterns for extraction\n",
        "pattern_matching = '''email, phone number, name'''\n",
        "\n",
        "# Extract patterns from the input text using the specified model and patterns\n",
        "extracted_patterns = extract_patterns(user_input, pattern_matching, model)\n",
        "\n",
        "# Print the extracted patterns\n",
        "print(extracted_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pRmAnmAYYl2n",
        "outputId": "3c8b1d9e-dd2f-49d6-9f9d-5690c3deaf68"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['123-456-7890', '523-456-7892', 'x123@gmail.com', 'fareed khan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Classification"
      ],
      "metadata": {
        "id": "Yz4UBg7-YtvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the analyze_sentiment function from the core_nlp module\n",
        "from core_nlp import analyze_sentiment\n",
        "\n",
        "# User input text\n",
        "user_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\n",
        "\n",
        "# Specify sentiment categories (optional, default includes 'positive, negative, neutral')\n",
        "category = \"positive, negative, neutral\"\n",
        "\n",
        "# Analyze sentiment in the text using the specified model and sentiment categories\n",
        "sentiment_result = analyze_sentiment(input_text=user_input, category=category, explanation=True, model=model)\n",
        "\n",
        "# Print the sentiment result\n",
        "print(sentiment_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "YvAVitAxYp3_",
        "outputId": "623af6a8-5df1-4a34-e1d5-f54436288e9e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Category: Negative**\n",
            "\n",
            "**Short Explanation:**\n",
            "\n",
            "The overall sentiment of the text is negative. The author starts by expressing a love for playing football, but then goes on to say that today they are feeling very sad and do not want to play football. This indicates a negative sentiment towards playing football today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the classify_topic function from the core_nlp module\n",
        "from core_nlp import classify_topic\n",
        "\n",
        "# User input text\n",
        "user_input = \"I love to play football, but today I am feeling very sad. I do not want to play football today.\"\n",
        "\n",
        "# Specify topics (optional, default includes 'story, horror, comedy')\n",
        "topics = \"story, horror, comedy\"\n",
        "\n",
        "# Classify the topic of the text using the specified model and topics\n",
        "topic_result = classify_topic(input_text=user_input, topics=topics, explanation=True, model=model)\n",
        "\n",
        "# Print the topic result\n",
        "print(topic_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "b55rnT85YvHB",
        "outputId": "34e2d370-c3af-458d-c8e3-2c4091d5d30d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic: Story\n",
            "\n",
            "Explanation: The input text is a short story about a person who loves to play football but is feeling sad and does not want to play today. This is a common theme in stories, where the protagonist faces a challenge or obstacle that they must overcome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the detect_spam function from the core_nlp module\n",
        "from core_nlp import detect_spam\n",
        "\n",
        "# User input text\n",
        "user_input = \"you have just won $14000, claim this award here at this link.\"\n",
        "\n",
        "# Specify spam categories (optional, default includes 'spam, not_spam, unknown')\n",
        "category = 'spam, not_spam, unknown'\n",
        "\n",
        "# Detect spam in the text using the specified model and spam categories\n",
        "spam_result = detect_spam(input_text=user_input, category=category, explanation=True, model=model)\n",
        "\n",
        "# Print the spam result\n",
        "print(spam_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "IPaMNV5VY5Tx",
        "outputId": "0d6a6538-4440-4673-aaca-c953d304ace6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spam\n",
            "\n",
            "Explanation: The text contains an unsolicited offer of a large sum of money, which is a common tactic used in spam emails. The link provided is likely malicious and could lead to the user's personal information being stolen or their computer being infected with malware.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Role Labeling (SRL)"
      ],
      "metadata": {
        "id": "3tV-LRj_Y7hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the perform_srl function from the core_nlp module\n",
        "from core_nlp import perform_srl\n",
        "\n",
        "# User input text\n",
        "user_input = \"tornado is approaching the city, please take shelter\"\n",
        "\n",
        "# Perform Semantic Role Labeling (SRL) on the text using the specified model\n",
        "srl_result = perform_srl(user_input, model)\n",
        "\n",
        "# Print the SRL result\n",
        "print(srl_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "rLcbAzr7Y6ja",
        "outputId": "9a0b3f6f-c557-432d-bf6a-f3e54ffbdc97"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicate: approaching\n",
            "Roles:\n",
            "- Agent: tornado\n",
            "- Theme: city\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intent Recognition"
      ],
      "metadata": {
        "id": "MLFo9ULwY-0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the recognize_intent function from the core_nlp module\n",
        "from core_nlp import recognize_intent\n",
        "\n",
        "# User input text\n",
        "user_input = \"tornado is approaching the city, please take shelter\"\n",
        "\n",
        "# Recognize intent in the text using the specified model\n",
        "intent_result = recognize_intent(user_input, model)\n",
        "\n",
        "# Print the intent result\n",
        "print(intent_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "WVOL7Fd-Y9T0",
        "outputId": "cef425df-2b02-4957-b628-c83ced93b176"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intent: Take shelter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Handling Large Data"
      ],
      "metadata": {
        "id": "N1pgZgAaZGpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example text dataset\n",
        "text_dataset = \"some_big_text_file.txt\"\n",
        "\n",
        "# Break the text into sentences based on full stops\n",
        "sentences = text_dataset.split('. ')\n",
        "\n",
        "# some ner_tags you have defined\n",
        "ner_tags = \"person, organization ...\"\n",
        "\n",
        "# Applying NER on it\n",
        "for i, sentence in enumerate(sentences):\n",
        "    print(f\"Sentence {i + 1}:\")\n",
        "\n",
        "    # Applying NER on each sentence\n",
        "    detect_ner(input_text=sentence, ner_tags=ner_tags, model=model)"
      ],
      "metadata": {
        "id": "tv57YaSTZALC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for paraphrase detection\n",
        "def paraphrasing_detection(input_text, explanation, model):\n",
        "\n",
        "    # Check if explanation is required\n",
        "    explanation_text = 'short explanation: ' if explanation else 'no explanation'\n",
        "\n",
        "    # Question to be asked for determining paraphrasing\n",
        "    question = f'''Given the input text, determine if two sentences are paraphrases of each other.\n",
        "    Sentence 1: {input_text[0]}\n",
        "    Sentence 2: {input_text[1]}\n",
        "    Answer must be 'yes' or 'no'.\n",
        "    {explanation_text}\n",
        "    '''\n",
        "\n",
        "    # Generate response\n",
        "    response = model.generate_content(question)\n",
        "    return response.text.strip()"
      ],
      "metadata": {
        "id": "b-uu26BOZJDx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the paraphrasing_detection function from the core_nlp module\n",
        "from core_nlp import paraphrasing_detection\n",
        "\n",
        "# User input text\n",
        "user_input = ['''The sun sets in the west every evening.''', '''Every evening, the sun goes down in the west.''']\n",
        "\n",
        "# Perform paraphrasing detection using the specified model\n",
        "intent_result = paraphrasing_detection(user_input, explanation=True, model=model)\n",
        "\n",
        "# Print the paraphrasing detection result\n",
        "print(intent_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "MxUsr6TgZN82",
        "outputId": "baeb869d-9499-49dc-f69c-927833acd6ea"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n",
            "Explanation:\n",
            "Sentence 1 and Sentence 2 convey the same meaning using different words. \"Sets\" and \"goes down\" are synonyms, and \"west\" refers to the same direction in both sentences. The time frame of \"every evening\" is also the same in both sentences. Therefore, the two sentences are paraphrases of each other.\n"
          ]
        }
      ]
    }
  ]
}