{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building a Sentiment Classifier using Scikit-Learn.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO3eH0owrwuVXmTF7Wgi9tm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NcS9ujIO5FB",
        "colab_type": "text"
      },
      "source": [
        "[Reference](https://github.com/lazuxd/simple-imdb-sentiment-analysis/blob/master/sentiment-analysis.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wq0Exe9O3P-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3b46b6f1-217f-4f5c-8f1a-92e807cfaf1d"
      },
      "source": [
        "!wget \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-08 15:01:07--  http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  17.3MB/s    in 10s     \n",
            "\n",
            "2020-09-08 15:01:17 (7.80 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1m0UP8WO8ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf \"aclImdb_v1.tar.gz\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpoT7GTVPA93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from random import shuffle"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaQIqNngPLBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data_frame(folder: str) -> pd.DataFrame:\n",
        "    '''\n",
        "    folder - the root folder of train or test dataset\n",
        "    Returns: a DataFrame with the combined data from the input folder\n",
        "    '''\n",
        "    pos_folder = f'{folder}/pos' # positive reviews\n",
        "    neg_folder = f'{folder}/neg' # negative reviews\n",
        "    \n",
        "    def get_files(fld: str) -> list:\n",
        "        '''\n",
        "        fld - positive or negative reviews folder\n",
        "        Returns: a list with all files in input folder\n",
        "        '''\n",
        "        return [join(fld, f) for f in listdir(fld) if isfile(join(fld, f))]\n",
        "    \n",
        "    def append_files_data(data_list: list, files: list, label: int) -> None:\n",
        "        '''\n",
        "        Appends to 'data_list' tuples of form (file content, label)\n",
        "        for each file in 'files' input list\n",
        "        '''\n",
        "        for file_path in files:\n",
        "            with open(file_path, 'r') as f:\n",
        "                text = f.read()\n",
        "                data_list.append((text, label))\n",
        "    \n",
        "    pos_files = get_files(pos_folder)\n",
        "    neg_files = get_files(neg_folder)\n",
        "    \n",
        "    data_list = []\n",
        "    append_files_data(data_list, pos_files, 1)\n",
        "    append_files_data(data_list, neg_files, 0)\n",
        "    shuffle(data_list)\n",
        "    \n",
        "    text, label = tuple(zip(*data_list))\n",
        "    # replacing line breaks with spaces\n",
        "    text = list(map(lambda txt: re.sub('(<br\\s*/?>)+', ' ', txt), text))\n",
        "    \n",
        "    return pd.DataFrame({'text': text, 'label': label})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8aLitjbPM2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_train = create_data_frame('aclImdb/train')\n",
        "imdb_test = create_data_frame('aclImdb/test')\n",
        "\n",
        "# !mkdir 'csv'\n",
        "# imdb_train.to_csv('csv/imdb_train.csv', index=False)\n",
        "# imdb_test.to_csv('csv/imdb_test.csv', index=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1u9x7vRPS5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from joblib import dump, load # used for saving and loading sklearn objects\n",
        "from scipy.sparse import save_npz, load_npz # used for saving and loading sparse matrices"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc_RT43APh8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir 'data_preprocessors'\n",
        "# !mkdir 'vectorized_data'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yuriwB4PmDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "df94f728-998c-461d-9a5d-51b7126136c3"
      },
      "source": [
        "unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
        "unigram_vectorizer.fit(imdb_train['text'].values)\n",
        "\n",
        "# dump(unigram_vectorizer, 'data_preprocessors/unigram_vectorizer.joblib')\n",
        "# unigram_vectorizer = load('data_preprocessors/unigram_vectorizer.joblib')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO3n61YvPp6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_unigram = unigram_vectorizer.transform(imdb_train['text'].values)\n",
        "\n",
        "# save_npz('vectorized_data/X_train_unigram.npz', X_train_unigram)\n",
        "\n",
        "# X_train_unigram = load_npz('vectorized_data/X_train_unigram.npz')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSqClBbIPsR4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c85ac14-b946-48a3-d218-29a47f341b69"
      },
      "source": [
        "unigram_tf_idf_transformer = TfidfTransformer()\n",
        "unigram_tf_idf_transformer.fit(X_train_unigram)\n",
        "\n",
        "# dump(unigram_tf_idf_transformer, 'data_preprocessors/unigram_tf_idf_transformer.joblib')\n",
        "\n",
        "# unigram_tf_idf_transformer = load('data_preprocessors/unigram_tf_idf_transformer.joblib')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0kmS9wtPufv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_unigram_tf_idf = unigram_tf_idf_transformer.transform(X_train_unigram)\n",
        "\n",
        "# save_npz('vectorized_data/X_train_unigram_tf_idf.npz', X_train_unigram_tf_idf)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGWljZ4pPy2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "008a839d-aaf9-41f8-8352-08385b71ed25"
      },
      "source": [
        "bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "bigram_vectorizer.fit(imdb_train['text'].values)\n",
        "\n",
        "# dump(bigram_vectorizer, 'data_preprocessors/bigram_vectorizer.joblib')\n",
        "\n",
        "# bigram_vectorizer = load('data_preprocessors/bigram_vectorizer.joblib')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOiw64N0QGuf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_bigram = bigram_vectorizer.transform(imdb_train['text'].values)\n",
        "\n",
        "# save_npz('vectorized_data/X_train_bigram.npz', X_train_bigram)\n",
        "\n",
        "# X_train_bigram = load_npz('vectorized_data/X_train_bigram.npz')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H845olUPP2zU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "70783124-938f-4326-bf0c-731a7933c9df"
      },
      "source": [
        "bigram_tf_idf_transformer = TfidfTransformer()\n",
        "bigram_tf_idf_transformer.fit(X_train_bigram)\n",
        "\n",
        "# dump(bigram_tf_idf_transformer, 'data_preprocessors/bigram_tf_idf_transformer.joblib')\n",
        "\n",
        "# bigram_tf_idf_transformer = load('data_preprocessors/bigram_tf_idf_transformer.joblib')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU1eIXMgP4PC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_bigram_tf_idf = bigram_tf_idf_transformer.transform(X_train_bigram)\n",
        "\n",
        "# save_npz('vectorized_data/X_train_bigram_tf_idf.npz', X_train_bigram_tf_idf)\n",
        "\n",
        "# X_train_bigram_tf_idf = load_npz('vectorized_data/X_train_bigram_tf_idf.npz')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJusWtnbP57F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.sparse import csr_matrix\n",
        "import numpy as np"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X58lvQ-QLny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
        "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X, y, train_size=0.75, stratify=y\n",
        "    )\n",
        "\n",
        "    clf = SGDClassifier()\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_score = clf.score(X_train, y_train)\n",
        "    valid_score = clf.score(X_valid, y_valid)\n",
        "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlTqsz47QM7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = imdb_train['label'].values"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wvi32GzSQO9_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "977e0189-f56d-4264-ca8e-906707d50731"
      },
      "source": [
        "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
        "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
        "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
        "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unigram Counts\n",
            "Train score: 1.0 ; Validation score: 0.87\n",
            "\n",
            "Unigram Tf-Idf\n",
            "Train score: 0.95 ; Validation score: 0.89\n",
            "\n",
            "Bigram Counts\n",
            "Train score: 1.0 ; Validation score: 0.88\n",
            "\n",
            "Bigram Tf-Idf\n",
            "Train score: 0.98 ; Validation score: 0.89\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l-WUc6JQQYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNvcspPLQTBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train_bigram_tf_idf"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8rq4JCuQaar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = SGDClassifier()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bheOe5ZyQUBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distributions = dict(\n",
        "    loss=['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
        "    learning_rate=['optimal', 'invscaling', 'adaptive'],\n",
        "    eta0=uniform(loc=1e-7, scale=1e-2)\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIs5V_5kQcAW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3b4dd9e7-8a48-4ee4-bbaa-b776028e9e17"
      },
      "source": [
        "random_search_cv = RandomizedSearchCV(\n",
        "    estimator=clf,\n",
        "    param_distributions=distributions,\n",
        "    cv=5,\n",
        "    n_iter=50\n",
        ")\n",
        "random_search_cv.fit(X_train, y_train)\n",
        "print(f'Best params: {random_search_cv.best_params_}')\n",
        "print(f'Best score: {random_search_cv.best_score_}')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: {'eta0': 0.0025605574520867493, 'learning_rate': 'optimal', 'loss': 'modified_huber'}\n",
            "Best score: 0.9051200000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnwyIFA9QdjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = SGDClassifier()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuDbK6gVQelo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distributions = dict(\n",
        "    penalty=['l1', 'l2', 'elasticnet'],\n",
        "    alpha=uniform(loc=1e-6, scale=1e-4)\n",
        ")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw82JXS3QgyB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a268d7fe-0010-4b36-93d0-000190d2f62e"
      },
      "source": [
        "random_search_cv = RandomizedSearchCV(\n",
        "    estimator=clf,\n",
        "    param_distributions=distributions,\n",
        "    cv=5,\n",
        "    n_iter=50\n",
        ")\n",
        "random_search_cv.fit(X_train, y_train)\n",
        "print(f'Best params: {random_search_cv.best_params_}')\n",
        "print(f'Best score: {random_search_cv.best_score_}')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params: {'alpha': 2.8720080757728263e-05, 'penalty': 'l2'}\n",
            "Best score: 0.90816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzsZvQglQkC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !mkdir 'classifiers'\n",
        "\n",
        "sgd_classifier = random_search_cv.best_estimator_\n",
        "\n",
        "# dump(random_search_cv.best_estimator_, 'classifiers/sgd_classifier.joblib')\n",
        "\n",
        "# sgd_classifier = load('classifiers/sgd_classifier.joblib')"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYEJv8v6QsYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = bigram_vectorizer.transform(imdb_test['text'].values)\n",
        "X_test = bigram_tf_idf_transformer.transform(X_test)\n",
        "y_test = imdb_test['label'].values"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M34NYsBnQtso",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daadadf6-0113-4bb7-d9ff-e87a04078f24"
      },
      "source": [
        "score = sgd_classifier.score(X_test, y_test)\n",
        "print(score)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9028\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}