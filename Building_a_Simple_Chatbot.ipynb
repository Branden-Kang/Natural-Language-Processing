{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building a Simple Chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPO8qfrXE6kt9fdX3/CyGs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyBVLjY7H6_S",
        "colab_type": "text"
      },
      "source": [
        "# Building a Simple Chatbot from Scratch in Python (using NLTK)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edunUspbK5rH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11d54c4d-fb76-4dce-cfcc-a71528f4ec5f"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "!pwd\n",
        "os.chdir('gdrive/My Drive/Colab Notebooks/')\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content\n",
            "/content/gdrive/My Drive/Colab Notebooks\n",
            " abcnews-date-text.csv\n",
            "'A method to categorical variable in flight delay datasets.ipynb'\n",
            " assignment0.ipynb\n",
            "'assignment2_(release).ipynb'\n",
            " assignment2_sol.ipynb\n",
            " chatbot.txt\n",
            "'Concrete Compressive Strength Prediction.ipynb'\n",
            "'Copy of Lecture_6_in_class.ipynb'\n",
            " corpus\n",
            " dask.ipynb\n",
            " datasets\n",
            "'Data Visualization'\n",
            "'Deep Q-learning.ipynb'\n",
            " Econometrics\n",
            "'Exploratory Data Analysis for Natural Language Processing.ipynb'\n",
            " Final_Project.ipynb\n",
            "'Flight Delay Analysis.ipynb'\n",
            " Flight_Delay_Analysis_Using_H2O.ipynb\n",
            " f_test.dec\n",
            " f_test.enc\n",
            " f_train.dec\n",
            " f_train.enc\n",
            " gbm_def\n",
            " gdrive\n",
            " glm_def\n",
            " Glove_solution.ipynb\n",
            " korea.jpg\n",
            " Lime_Machine_Learning\n",
            " load_n_demo.ipynb\n",
            " loss_female_epo200.npy\n",
            " loss_female_epo2.npy\n",
            " loss_female_epo40.npy\n",
            " loss_female_epo4.npy\n",
            " loss_female_epo5.npy\n",
            " loss_female_sche_sampling_epo1.npy\n",
            " loss_female_sche_sampling_epo200.npy\n",
            " loss_female_sche_sampling_epo2.npy\n",
            " loss_male_epo200.npy\n",
            " loss_male_epo2.npy\n",
            " loss_male_epo5.npy\n",
            " loss_male_prob_feed_epo200.npy\n",
            " loss_male_sche_sampling_epo200.npy\n",
            " loss.png\n",
            " main.py\n",
            " Market-Mix-Modelling.ipynb\n",
            "'ML Practice'\n",
            " MMM.xlsx\n",
            "'Model 4 generator'\n",
            "'Model 5 RL'\n",
            " model_female_prob_feed_epo141.pth\n",
            " model_female_prob_feed_epo199.pth\n",
            " model_female_prob_feed_epo200.pth\n",
            "'Optimization Methods in Machine Learning'\n",
            "'Project Choice #1.ipynb'\n",
            " pth\n",
            " Schedule_Sampling_Seq2Seq-female.ipynb\n",
            "'Schedule Sampling Seq2Seq-Movie_Script Chatbot-PyTorch.ipynb'\n",
            "'Time Series Analysis.ipynb'\n",
            " Untitled0.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtb4X6CmH9MJ",
        "colab_type": "text"
      },
      "source": [
        "## Import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYUE_k0VH9CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import string # to process standard python strings\n",
        "import io\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2AQhgHkHZ0s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57df40dc-e4e4-4380-dd8e-9c70cd1b7bf4"
      },
      "source": [
        "!pip install nltk "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63hMLs1jLFpV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "80e11f91-4155-47e9-9cef-63e81f6dd894"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True) # for downloading packages\n",
        "nltk.download('punkt') # first-time use only\n",
        "nltk.download('wordnet') # first-time use only"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHx-2BMNLLeg",
        "colab_type": "text"
      },
      "source": [
        "## Reading in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIx0Tz6yLH1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f=open('chatbot.txt','r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw = raw.lower()# converts to lowercase"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18AQcdm8LS8X",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez72iFmmLPZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw) # converts to list of sentences \n",
        "word_tokens = nltk.word_tokenize(raw) # converts to list of words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtGHGG13LjA2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a970141b-7c38-4f15-94fd-70e6e99e816a"
      },
      "source": [
        "sent_tokens[:2]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a chatbot (also known as a talkbot, chatterbot, bot, im bot, interactive agent, or artificial conversational entity) is a computer program or an artificial intelligence which conducts a conversation via auditory or textual methods.',\n",
              " 'such programs are often designed to convincingly simulate how a human would behave as a conversational partner, thereby passing the turing test.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5yBDSiVLkhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0148cae4-3c95-4503-bdb2-7a7be0f13b4a"
      },
      "source": [
        "word_tokens[:2]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'chatbot']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtbZVJfJLXg1",
        "colab_type": "text"
      },
      "source": [
        "# Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH4YuVkTLVQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0RJBADpLxaJ",
        "colab_type": "text"
      },
      "source": [
        "## Keyword matching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdqfgrxNLdOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def greeting(sentence):\n",
        " \n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfuWLqL-L5pw",
        "colab_type": "text"
      },
      "source": [
        "## Generating Response\n",
        "### Bag of Words: a representation of text that describes the occurrence of words within a document.\n",
        "### TF-IDF Approach: rescale the frequency of words by how often they appear in all documents so that the scores for frequent words like “the” that are also frequent across all documents are penalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmLl0QVKMhir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opv45mO-L4Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bc3XnM3MRod",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "5416e32e-6519-488c-a17b-07d69f9590c2"
      },
      "source": [
        "flag=True\n",
        "print(\"ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you' ):\n",
        "            flag=False\n",
        "            print(\"ROBO: You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO: \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO: \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"ROBO: Bye! take care..\")\n",
        "# What is a chatbot?\n",
        "# What is ELIZA?\n",
        "# Who coined the term chatbot?\n",
        "# Are Chatbots any good?\n",
        "# Bye"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROBO: My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
            "What is a chatbot?\n",
            "ROBO: design\n",
            "the chatbot design is the process that defines the interaction between the user and the chatbot.the chatbot designer will define the chatbot personality, the questions that will be asked to the users, and the overall interaction.it can be viewed as a subset of the conversational design.\n",
            "What is ELIZA?\n",
            "ROBO: while eliza and parry were used exclusively to simulate typed conversation, many chatbots now include functional features such as games and web searching abilities.\n",
            "Who coined the term chatbot?\n",
            "ROBO: the term \"chatterbot\" was originally coined by michael mauldin (creator of the first verbot, julia) in 1994 to describe these conversational programs.today, most chatbots are either accessed via virtual assistants such as google assistant and amazon alexa, via messaging apps such as facebook messenger or wechat, or via individual organizations' apps and websites.\n",
            "Are Chatbots any good?\n",
            "ROBO: in 2016, facebook messenger allowed developers to place chatbots on their platform.\n",
            "Bye\n",
            "ROBO: Bye! take care..\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}