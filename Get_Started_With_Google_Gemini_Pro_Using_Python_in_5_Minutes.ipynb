{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKRpwgV+34gu7Vr2pmoM8G"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://pub.towardsai.net/get-started-with-google-gemini-pro-using-python-in-5-minutes-00700244f58a)"
      ],
      "metadata": {
        "id": "ThJMZVu4bB4O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIhdxHf7azwR",
        "outputId": "0b5d10a8-c64e-4779-ee63-d31d43d24ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/137.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "with open('gemini_key.yml', 'r') as file:\n",
        "    api_creds = yaml.safe_load(file)\n",
        "\n",
        "GOOGLE_API_KEY = api_creds['gemini_key']"
      ],
      "metadata": {
        "id": "efLiKlyUbFiN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "VHvnod3obHVw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Explain Generative AI with 3 bullet points\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "0GZLAczfbIFt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "it_support_queue = [\n",
        "    \"I can't access my email. It keeps showing an error message. Please help.\",\n",
        "    \"Tengo problemas con la VPN. No puedo conectarme a la red de la empresa. ¿Pueden ayudarme, por favor?\",\n",
        "    \"Mon imprimante ne répond pas et n'imprime plus. J'ai besoin d'aide pour la réparer.\",\n",
        "    \"Eine wichtige Software stürzt ständig ab und beeinträchtigt meine Arbeit. Können Sie das Problem beheben?\",\n",
        "    \"我无法访问公司的网站。每次都显示错误信息。请帮忙解决。\"\n",
        "]\n",
        "\n",
        "it_support_queue_msgs = f\"\"\"\n",
        "\"\"\"\n",
        "for i, msg in enumerate(it_support_queue):\n",
        "  it_support_queue_msgs += \"\\nMessage \" + str(i+1) + \": \" + msg\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Act as a customer support agent. Remember to ask for relevant information based on the customer issue to solve the problem.\n",
        "Don't deny them help without asking for relevant information. For each support message mentioned below\n",
        "in triple backticks, create a response as a table with the following columns:\n",
        "\n",
        "\n",
        "  orig_msg: The original customer message\n",
        "  orig_lang: Detected language of the customer message e.g. Spanish\n",
        "  trans_msg: Translated customer message in English\n",
        "  response: Response to the customer in orig_lang\n",
        "  trans_response: Response to the customer in English\n",
        "\n",
        "\n",
        "Messages:\n",
        "'''{it_support_queue_msgs}'''\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "eXZM_awBbJtk"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}