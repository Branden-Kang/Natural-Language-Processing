{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introducing NLPretext.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN9NplBAQFsF1uSnyUTpoxi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/artefact-engineering-and-data-science/introducing-nlpretext-a8bb7c03df89)"
      ],
      "metadata": {
        "id": "j-Xwe6U6RL7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nlpretext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6nOIeLUiRTnz",
        "outputId": "cbfb8267-211a-4961-cb30-ed52e4533549"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlpretext\n",
            "  Downloading nlpretext-1.1.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 2.6 MB/s \n",
            "\u001b[?25hCollecting fastparquet>=0.4.1\n",
            "  Downloading fastparquet-0.7.2-cp37-cp37m-manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 16.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>1.15.4 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (1.19.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (1.1.5)\n",
            "Collecting sacremoses>=0.0.13\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 34.8 MB/s \n",
            "\u001b[?25hCollecting mosestokenizer>=1.1.0\n",
            "  Downloading mosestokenizer-1.2.1.tar.gz (37 kB)\n",
            "Collecting flashtext>=2.7\n",
            "  Downloading flashtext-2.7.tar.gz (14 kB)\n",
            "Collecting emoji>=0.5.2\n",
            "  Downloading emoji-1.6.1.tar.gz (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 42.9 MB/s \n",
            "\u001b[?25hCollecting dask[complete]>=2021.5.0\n",
            "  Downloading dask-2021.12.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 31.1 MB/s \n",
            "\u001b[?25hCollecting phonenumbers>=8.10.12\n",
            "  Downloading phonenumbers-8.12.39-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 27.3 MB/s \n",
            "\u001b[?25hCollecting pyarrow>=4.0.0\n",
            "  Downloading pyarrow-6.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.6 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting ftfy>=4.2.0\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting tornado>=6.0.3\n",
            "  Downloading tornado-6.1-cp37-cp37m-manylinux2010_x86_64.whl (428 kB)\n",
            "\u001b[K     |████████████████████████████████| 428 kB 57.5 MB/s \n",
            "\u001b[?25hCollecting spacy>=3.0.5\n",
            "  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 56.6 MB/s \n",
            "\u001b[?25hCollecting stop-words>=2018.7.23\n",
            "  Downloading stop-words-2018.7.23.tar.gz (31 kB)\n",
            "Collecting rich>=10.1.0\n",
            "  Downloading rich-10.15.2-py3-none-any.whl (214 kB)\n",
            "\u001b[K     |████████████████████████████████| 214 kB 38.5 MB/s \n",
            "\u001b[?25hCollecting typer[all]>=0.3.2\n",
            "  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: regex>=2019.8.19 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (2019.12.20)\n",
            "Collecting pillow>=8.2.1\n",
            "  Downloading Pillow-8.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 37.7 MB/s \n",
            "\u001b[?25hCollecting distributed>=2021.5.0\n",
            "  Downloading distributed-2021.12.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting nlpaug>=1.0.1\n",
            "  Downloading nlpaug-1.1.9-py3-none-any.whl (408 kB)\n",
            "\u001b[K     |████████████████████████████████| 408 kB 41.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (4.8.2)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.7/dist-packages (from nlpretext) (1.0.1)\n",
            "Collecting nltk<3.6,>=3.4.2\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 43.1 MB/s \n",
            "\u001b[?25hCollecting thinc>=8.0.4\n",
            "  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n",
            "\u001b[K     |████████████████████████████████| 628 kB 50.2 MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=2021.5.0->nlpretext) (3.13)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=2021.5.0->nlpretext) (1.3.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=2021.5.0->nlpretext) (21.3)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=2021.5.0->nlpretext) (0.11.2)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 57.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bokeh>=2.1.1 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=2021.5.0->nlpretext) (2.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from dask[complete]>=2021.5.0->nlpretext) (2.11.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (2.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (5.4.8)\n",
            "Collecting cloudpickle>=1.1.1\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (7.1.2)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (2.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (57.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (1.0.3)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2021.5.0->nlpretext) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]>=2021.5.0->nlpretext) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh>=2.1.1->dask[complete]>=2021.5.0->nlpretext) (3.10.0.2)\n",
            "Collecting thrift>=0.11.0\n",
            "  Downloading thrift-0.15.0.tar.gz (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 5.8 MB/s \n",
            "\u001b[?25hCollecting cramjam>=2.3.0\n",
            "  Downloading cramjam-2.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 33.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy>=4.2.0->nlpretext) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib_metadata>=1.6.0->nlpretext) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->dask[complete]>=2021.5.0->nlpretext) (2.0.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from mosestokenizer>=1.1.0->nlpretext) (0.6.2)\n",
            "Collecting openfile\n",
            "  Downloading openfile-0.0.7-py3-none-any.whl (2.4 kB)\n",
            "Collecting uctools\n",
            "  Downloading uctools-1.3.0.tar.gz (4.6 kB)\n",
            "Collecting toolwrapper\n",
            "  Downloading toolwrapper-2.1.0.tar.gz (3.2 kB)\n",
            "Collecting pandas>=1.1.5\n",
            "  Downloading pandas-1.3.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 51.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.7/dist-packages (from nlpaug>=1.0.1->nlpretext) (2.23.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<3.6,>=3.4.2->nlpretext) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<3.6,>=3.4.2->nlpretext) (4.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->dask[complete]>=2021.5.0->nlpretext) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->nlpretext) (2018.9)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh>=2.1.1->dask[complete]>=2021.5.0->nlpretext) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug>=1.0.1->nlpretext) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug>=1.0.1->nlpretext) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.22.0->nlpaug>=1.0.1->nlpretext) (2.10)\n",
            "Collecting colorama<0.5.0,>=0.4.0\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.1.0->nlpretext) (2.6.1)\n",
            "Collecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->nlpretext) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.23.2->nlpretext) (3.0.0)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.5->nlpretext) (0.4.1)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n",
            "\u001b[K     |████████████████████████████████| 451 kB 58.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.5->nlpretext) (3.0.6)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.5->nlpretext) (2.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.5->nlpretext) (1.0.6)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=3.0.5->nlpretext) (0.8.2)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 59.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=3.0.5->nlpretext) (5.2.1)\n",
            "Collecting shellingham<2.0.0,>=1.3.0\n",
            "  Downloading shellingham-1.4.0-py2.py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2021.5.0->nlpretext) (1.0.1)\n",
            "Building wheels for collected packages: emoji, flashtext, ftfy, mosestokenizer, nltk, stop-words, thrift, toolwrapper, uctools\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169314 sha256=4411a9459ed8b140a84b49872fe8e6443fb6be1dc861427ace66ae04a6899824\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/5f/d3/03d313ddb3c2a1a427bb4690f1621eea60fe6f2a30cc95940f\n",
            "  Building wheel for flashtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flashtext: filename=flashtext-2.7-py2.py3-none-any.whl size=9310 sha256=7d20400bda6183de5a1c608594d7199affe078e9ddf431487af2200e60be4a47\n",
            "  Stored in directory: /root/.cache/pip/wheels/cb/19/58/4e8fdd0009a7f89dbce3c18fff2e0d0fa201d5cdfd16f113b7\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=52b230862b798d7405c87db6ba953a7ce94f1ca7cb14f4c6552fde56ea44ed6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "  Building wheel for mosestokenizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mosestokenizer: filename=mosestokenizer-1.2.1-py3-none-any.whl size=49188 sha256=cf1359e8715ac12cd7dec52efe7b2f8f4df6c16c0dd2d44c03c4702669eca7c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/35/f7/af1258779a0b890abc3c79481460c597cb1f3659d0603cfb9d\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434690 sha256=03f51b6a977504c45fefdf3c9b61ba01762013aeb1bec6582bd475e6639a9603\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-py3-none-any.whl size=32912 sha256=a509657a79c32eb254834e3c5a6678b3064f20bfcca29b142d44be3a62754410\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/86/b2/277b10b1ce9f73ce15059bf6975d4547cc4ec3feeb651978e9\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thrift: filename=thrift-0.15.0-cp37-cp37m-linux_x86_64.whl size=348195 sha256=177c882c009bf93e5f026fccd62e91eb8ccfec20f3ae6a03999bad255d6d8095\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/1f/8e/e6fd36837eecf3d1f2b23f1729477e8e06558d8d60b7093f51\n",
            "  Building wheel for toolwrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for toolwrapper: filename=toolwrapper-2.1.0-py3-none-any.whl size=3354 sha256=862650b3f9a1acbbfa8d0ddb9cb090e8df93e3ec4ccf3761a45e65e6c34e40fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/4f/33/54741ffe08e38ececb1d28068a153729b4fe820bafa0a0691f\n",
            "  Building wheel for uctools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for uctools: filename=uctools-1.3.0-py3-none-any.whl size=6163 sha256=0d9dd370f372589507dd3ea20e1e389efdac3cf326339080eb5bc571f6435d9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/44/e9/914cf8fa71f0141f9314f862538d1218fcf2b94542a0fb7d35\n",
            "Successfully built emoji flashtext ftfy mosestokenizer nltk stop-words thrift toolwrapper uctools\n",
            "Installing collected packages: locket, partd, fsspec, cloudpickle, catalogue, typer, tornado, srsly, pydantic, pillow, dask, uctools, toolwrapper, thrift, thinc, spacy-loggers, spacy-legacy, shellingham, pathy, pandas, openfile, langcodes, distributed, cramjam, commonmark, colorama, stop-words, spacy, sacremoses, rich, pyarrow, phonenumbers, nltk, nlpaug, mosestokenizer, ftfy, flashtext, fastparquet, emoji, nlpretext\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: tornado\n",
            "    Found existing installation: tornado 5.1.1\n",
            "    Uninstalling tornado-5.1.1:\n",
            "      Successfully uninstalled tornado-5.1.1\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 3.0.0\n",
            "    Uninstalling pyarrow-3.0.0:\n",
            "      Successfully uninstalled pyarrow-3.0.0\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed catalogue-2.0.6 cloudpickle-2.0.0 colorama-0.4.4 commonmark-0.9.1 cramjam-2.5.0 dask-2021.12.0 distributed-2021.12.0 emoji-1.6.1 fastparquet-0.7.2 flashtext-2.7 fsspec-2021.11.1 ftfy-6.0.3 langcodes-3.3.0 locket-0.2.1 mosestokenizer-1.2.1 nlpaug-1.1.9 nlpretext-1.1.0 nltk-3.5 openfile-0.0.7 pandas-1.3.4 partd-1.2.0 pathy-0.6.1 phonenumbers-8.12.39 pillow-8.4.0 pyarrow-6.0.1 pydantic-1.8.2 rich-10.15.2 sacremoses-0.0.46 shellingham-1.4.0 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 stop-words-2018.7.23 thinc-8.0.13 thrift-0.15.0 toolwrapper-2.1.0 tornado-6.1 typer-0.4.0 uctools-1.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "pandas",
                  "tornado"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4kTXS10RJlr",
        "outputId": "f23f4778-5f73-4e65-883b-3b438c7d1476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I have forwarded this email to *EMAIL*\n"
          ]
        }
      ],
      "source": [
        "from nlpretext.basic.preprocess import replace_emails\n",
        "\n",
        "example = \"I have forwarded this email to obama@whitehouse.gov\"\n",
        "example = replace_emails(example, replace_with=\"*EMAIL*\")\n",
        "print(example)\n",
        "\n",
        "# \"I have forwarded this email to *EMAIL*\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpretext.social.preprocess import extract_emojis\n",
        "example = \"I take care of my skin 😀\"\n",
        "example = extract_emojis(example)\n",
        "print(example)\n",
        "# [':grinning_face:']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BM63RukRPtJ",
        "outputId": "9c3bd00e-6124-4d9f-9e3c-8eebc5a3b279"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[':grinning_face:']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpretext.token.preprocess import remove_stopwords\n",
        "example = [\"I\", \"like\", \"when\", \"you\", \"move\", \"your\", \"body\"]\n",
        "example = remove_stopwords(example, lang=\"en\")\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxlMHpjlRXSR",
        "outputId": "c192c052-0ccb-404f-8525-d552c6c6ced8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I', 'move', 'body']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwD1DPSaRx3r",
        "outputId": "a26fdb68-87bf-4721-9055-87b4e295718e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpretext.augmentation.text_augmentation import augment_text\n",
        "example = \"I want to buy a small black handbag please.\"\n",
        "entities = [{'entity': 'Color', 'word': 'black', 'startCharIndex': 22, 'endCharIndex': 27}]\n",
        "example = augment_text(example, method=\"wordnet_synonym\", entities=entities)\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cltE53aHRbed",
        "outputId": "b42767b9-8407-45ca-8f5e-fe8089ca8794"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Iodine need to buy a small black handbag please.', [{'endCharIndex': 32, 'word': 'black', 'startCharIndex': 27, 'entity': 'Color'}])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpretext import Preprocessor\n",
        "text = \"I just got the best dinner in my life @latourdargent !!! I  recommend 😀 #food #paris \\n\"\n",
        "preprocessor = Preprocessor()\n",
        "text = preprocessor.run(text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "012YOKvFRd7a",
        "outputId": "c1700fa8-5cc9-4a33-e586-8891c9e82cb9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I just got the best dinner in my life !!! I recommend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nlpretext import Preprocessor\n",
        "from nlpretext.basic.preprocess import (normalize_whitespace, remove_punct, remove_eol_characters, remove_stopwords, lower_text)\n",
        "from nlpretext.social.preprocess import remove_mentions, remove_hashtag, remove_emoji\n",
        "text = \"I just got the best dinner in my life @latourdargent !!! I  recommend 😀 #food #paris \\n\"\n",
        "preprocessor = Preprocessor()\n",
        "preprocessor.pipe(lower_text)\n",
        "preprocessor.pipe(remove_mentions)\n",
        "preprocessor.pipe(remove_hashtag)\n",
        "preprocessor.pipe(remove_emoji)\n",
        "preprocessor.pipe(remove_eol_characters)\n",
        "preprocessor.pipe(remove_stopwords, args={'lang': 'en'})\n",
        "preprocessor.pipe(remove_punct)\n",
        "preprocessor.pipe(normalize_whitespace)\n",
        "text = preprocessor.run(text)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlV0psnxRfs8",
        "outputId": "84e89cb8-749e-4a80-afa2-44066584acce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dinner life recommend\n"
          ]
        }
      ]
    }
  ]
}