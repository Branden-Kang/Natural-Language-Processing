{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lemmatisation and Stemming in Python.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOBR4D5Qsx+tBSzQbeDxves"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tucvynL7c5dZ"
      },
      "source": [
        "[Reference](https://towardsdatascience.com/introduction-to-nlp-part-2-difference-between-lemmatisation-and-stemming-3789be1c55bc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVKmgCZYc11g",
        "outputId": "6217a502-0048-478c-f06a-6832b40a66fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkaD5Zglf07A"
      },
      "source": [
        "# Import packages\n",
        "import pandas as pd\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "# Instantiate stemmers and lemmatiser\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "\n",
        "# Create function that normalises text using all three techniques\n",
        "def normalise_text(words, pos='v'):\n",
        "    \"\"\"Stem and lemmatise each word in a list. Return output in a dataframe.\"\"\"\n",
        "    normalised_text = pd.DataFrame(index=words, columns=['Porter', 'Lancaster', 'Lemmatiser'])\n",
        "    for word in words:\n",
        "        normalised_text.loc[word,'Porter'] = porter.stem(word)\n",
        "        normalised_text.loc[word,'Lancaster'] = lancaster.stem(word)\n",
        "        normalised_text.loc[word,'Lemmatiser'] = lemmatiser.lemmatize(word, pos=pos)\n",
        "    return normalised_text"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78JxcI40f_D-",
        "outputId": "e3bd0d94-aeec-4c46-f290-7c7a3e814f16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "normalise_text(['apples', 'pears', 'tasks', 'children', 'earrings', 'dictionary', 'marriage', 'connections', 'universe', 'university'], pos='n')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Porter</th>\n",
              "      <th>Lancaster</th>\n",
              "      <th>Lemmatiser</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>apples</th>\n",
              "      <td>appl</td>\n",
              "      <td>appl</td>\n",
              "      <td>apple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pears</th>\n",
              "      <td>pear</td>\n",
              "      <td>pear</td>\n",
              "      <td>pear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tasks</th>\n",
              "      <td>task</td>\n",
              "      <td>task</td>\n",
              "      <td>task</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>children</th>\n",
              "      <td>children</td>\n",
              "      <td>childr</td>\n",
              "      <td>child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>earrings</th>\n",
              "      <td>ear</td>\n",
              "      <td>ear</td>\n",
              "      <td>earring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dictionary</th>\n",
              "      <td>dictionari</td>\n",
              "      <td>dict</td>\n",
              "      <td>dictionary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>marriage</th>\n",
              "      <td>marriag</td>\n",
              "      <td>marry</td>\n",
              "      <td>marriage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>connections</th>\n",
              "      <td>connect</td>\n",
              "      <td>connect</td>\n",
              "      <td>connection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>universe</th>\n",
              "      <td>univers</td>\n",
              "      <td>univers</td>\n",
              "      <td>universe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>university</th>\n",
              "      <td>univers</td>\n",
              "      <td>univers</td>\n",
              "      <td>university</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Porter Lancaster  Lemmatiser\n",
              "apples             appl      appl       apple\n",
              "pears              pear      pear        pear\n",
              "tasks              task      task        task\n",
              "children       children    childr       child\n",
              "earrings            ear       ear     earring\n",
              "dictionary   dictionari      dict  dictionary\n",
              "marriage        marriag     marry    marriage\n",
              "connections     connect   connect  connection\n",
              "universe        univers   univers    universe\n",
              "university      univers   univers  university"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5MxPG-IgBgR",
        "outputId": "0db2ee53-46b1-4b10-c14c-1ddc31c0a1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "normalise_text(['pie', 'globe', 'house', 'knee', 'angle', 'acetone', 'time', 'brownie', 'climate', 'independence'], pos='n')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Porter</th>\n",
              "      <th>Lancaster</th>\n",
              "      <th>Lemmatiser</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pie</th>\n",
              "      <td>pie</td>\n",
              "      <td>pie</td>\n",
              "      <td>pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>globe</th>\n",
              "      <td>globe</td>\n",
              "      <td>glob</td>\n",
              "      <td>globe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>house</th>\n",
              "      <td>hous</td>\n",
              "      <td>hous</td>\n",
              "      <td>house</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knee</th>\n",
              "      <td>knee</td>\n",
              "      <td>kne</td>\n",
              "      <td>knee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>angle</th>\n",
              "      <td>angl</td>\n",
              "      <td>angl</td>\n",
              "      <td>angle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acetone</th>\n",
              "      <td>aceton</td>\n",
              "      <td>aceton</td>\n",
              "      <td>acetone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>time</td>\n",
              "      <td>tim</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brownie</th>\n",
              "      <td>browni</td>\n",
              "      <td>browny</td>\n",
              "      <td>brownie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>climate</th>\n",
              "      <td>climat</td>\n",
              "      <td>clim</td>\n",
              "      <td>climate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>independence</th>\n",
              "      <td>independ</td>\n",
              "      <td>independ</td>\n",
              "      <td>independence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Porter Lancaster    Lemmatiser\n",
              "pie                pie       pie           pie\n",
              "globe            globe      glob         globe\n",
              "house             hous      hous         house\n",
              "knee              knee       kne          knee\n",
              "angle             angl      angl         angle\n",
              "acetone         aceton    aceton       acetone\n",
              "time              time       tim          time\n",
              "brownie         browni    browny       brownie\n",
              "climate         climat      clim       climate\n",
              "independence  independ  independ  independence"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMrPCCNDgOQR",
        "outputId": "1b2d7952-598e-4185-f444-eebeeaccdaaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "normalise_text(['wrote', 'thinking', 'remembered', 'relies', 'ate', 'gone', 'won', 'ran', 'swimming', 'mistreated'], pos='v')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Porter</th>\n",
              "      <th>Lancaster</th>\n",
              "      <th>Lemmatiser</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>wrote</th>\n",
              "      <td>wrote</td>\n",
              "      <td>wrot</td>\n",
              "      <td>write</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>thinking</th>\n",
              "      <td>think</td>\n",
              "      <td>think</td>\n",
              "      <td>think</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>remembered</th>\n",
              "      <td>rememb</td>\n",
              "      <td>rememb</td>\n",
              "      <td>remember</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>relies</th>\n",
              "      <td>reli</td>\n",
              "      <td>rely</td>\n",
              "      <td>rely</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ate</th>\n",
              "      <td>ate</td>\n",
              "      <td>at</td>\n",
              "      <td>eat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gone</th>\n",
              "      <td>gone</td>\n",
              "      <td>gon</td>\n",
              "      <td>go</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>won</th>\n",
              "      <td>won</td>\n",
              "      <td>won</td>\n",
              "      <td>win</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ran</th>\n",
              "      <td>ran</td>\n",
              "      <td>ran</td>\n",
              "      <td>run</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swimming</th>\n",
              "      <td>swim</td>\n",
              "      <td>swim</td>\n",
              "      <td>swim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mistreated</th>\n",
              "      <td>mistreat</td>\n",
              "      <td>mist</td>\n",
              "      <td>mistreat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Porter Lancaster Lemmatiser\n",
              "wrote          wrote      wrot      write\n",
              "thinking       think     think      think\n",
              "remembered    rememb    rememb   remember\n",
              "relies          reli      rely       rely\n",
              "ate              ate        at        eat\n",
              "gone            gone       gon         go\n",
              "won              won       won        win\n",
              "ran              ran       ran        run\n",
              "swimming        swim      swim       swim\n",
              "mistreated  mistreat      mist   mistreat"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPLvzgFmgc4r",
        "outputId": "f5997376-c1be-47f4-e095-fc18cdfa9b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "# Import data\n",
        "reviews = []\n",
        "for fileid in movie_reviews.fileids():\n",
        "    tag, filename = fileid.split('/')\n",
        "    reviews.append((tag, movie_reviews.raw(fileid)))\n",
        "sample = pd.DataFrame(reviews, columns=['target', 'document'])\n",
        "\n",
        "# Prepare one giant string \n",
        "sample_string = \" \".join(sample['document'].values)\n",
        "\n",
        "# Tokenise data\n",
        "tokeniser = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokeniser.tokenize(sample_string)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHzHx_1FicbW",
        "outputId": "b744660e-04d3-43b8-b074-28084038cb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit\n",
        "lemmatiser = WordNetLemmatizer()\n",
        "[lemmatiser.lemmatize(token, 'v') for token in tokens]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 4.73 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOcqLwzFgp87",
        "outputId": "989c6ee4-f198-45e4-c4d8-3a2fa918f594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit \n",
        "porter = PorterStemmer()\n",
        "[porter.stem(token) for token in tokens]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 20.4 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBZDN3fLg5Kd",
        "outputId": "c9162f1c-2a0c-4c9b-ecf2-83f5ab1566db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%timeit \n",
        "lancaster = LancasterStemmer()\n",
        "[lancaster.stem(token) for token in tokens]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 15.6 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNrs0SszhFYf"
      },
      "source": [
        "# Part-of-speech tag "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIbg1sKEg9ZN",
        "outputId": "e7203e5a-1640-4f2d-ec7a-f28f65057ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "lemmatiser = WordNetLemmatizer()\n",
        "print(f\"Lemmatising 'remembered' with pos='v' results in: {lemmatiser.lemmatize('remembered', 'v')}\")\n",
        "print(f\"Lemmatising 'remembered' with pos='n' results in: {lemmatiser.lemmatize('remembered', 'n')}\\n\")\n",
        "print(f\"Lemmatising 'universities' with pos='v' results in: {lemmatiser.lemmatize('universities', 'v')}\")\n",
        "print(f\"Lemmatising 'universities' with pos='n' results in: {lemmatiser.lemmatize('universities', 'n')}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmatising 'remembered' with pos='v' results in: remember\n",
            "Lemmatising 'remembered' with pos='n' results in: remembered\n",
            "\n",
            "Lemmatising 'universities' with pos='v' results in: universities\n",
            "Lemmatising 'universities' with pos='n' results in: university\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgysQUGHhHDd",
        "outputId": "1b128483-bf60-49ba-f78c-c4ab19f4335a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(f\"Lemmatising 'Remembered' with pos='v' results in: {lemmatiser.lemmatize('Remembered', 'v')}\")\n",
        "print(f\"Lemmatising 'Remembered' with pos='n' results in: {lemmatiser.lemmatize('Remembered', 'n')}\\n\")\n",
        "print(f\"Lemmatising 'Universities' with pos='v' results in: {lemmatiser.lemmatize('Universities', 'v')}\")\n",
        "print(f\"Lemmatising 'Universities' with pos='n' results in: {lemmatiser.lemmatize('Universities', 'n')}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmatising 'Remembered' with pos='v' results in: Remembered\n",
            "Lemmatising 'Remembered' with pos='n' results in: Remembered\n",
            "\n",
            "Lemmatising 'Universities' with pos='v' results in: Universities\n",
            "Lemmatising 'Universities' with pos='n' results in: Universities\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}