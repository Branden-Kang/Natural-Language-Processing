{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Zero to One : Sparse Document Representations.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7N0ZiRj29ZLRtfcgbxvGI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip1ULkJMj2Pv"
      },
      "source": [
        "[Reference](https://medium.com/nerd-for-tech/nlp-zero-to-one-sparse-document-representations-part-2-30-d7ce30b96d63)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgVsBmUNj4o2"
      },
      "source": [
        "# 1. Bag-of-Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HE4bH__tjy8u",
        "outputId": "2b771d8e-36c2-4c51-f793-80311b9b287b"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "docs = [\n",
        "        'a dog live in home',\n",
        "        'a dog live in the hut',\n",
        "        'hut is dog home'\n",
        "]\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(docs)\n",
        "print(f'Vocabulary: {list(tokenizer.word_index.keys())}')\n",
        "vectors = tokenizer.texts_to_matrix(docs, mode='count')\n",
        "print(vectors)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['dog', 'a', 'live', 'in', 'home', 'hut', 'the', 'is']\n",
            "[[0. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
            " [0. 1. 1. 1. 1. 0. 1. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 1. 1. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09rgZCkqkjQw"
      },
      "source": [
        "# 2. TF-IDF (Term Frequency- Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zPTtqrvlZ5n",
        "outputId": "f58616c6-6681-478f-a97d-ceb208a9f553"
      },
      "source": [
        "!pip install scikit-learn==0.13"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.13\n",
            "  Downloading scikit-learn-0.13.tar.gz (3.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 5.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: scikit-learn\n",
            "  Building wheel for scikit-learn (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for scikit-learn\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for scikit-learn\n",
            "Failed to build scikit-learn\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "    Running setup.py install for scikit-learn ... \u001b[?25l\u001b[?25herror\n",
            "  Rolling back uninstall of scikit-learn\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/scikit_learn-0.22.2.post1.dist-info/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~cikit_learn-0.22.2.post1.dist-info\n",
            "  Moving to /usr/local/lib/python3.7/dist-packages/sklearn/\n",
            "   from /usr/local/lib/python3.7/dist-packages/~klearn\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-romg7s99/scikit-learn_af415ce78ad84d00b10bb5fe9aa747a3/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-romg7s99/scikit-learn_af415ce78ad84d00b10bb5fe9aa747a3/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-p18waeix/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/scikit-learn Check the logs for full command output.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yTHxzprkO2Y",
        "outputId": "53b9c5e0-15f4-4411-d075-893310b30584"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "docs = [\n",
        "        'a dog live in home',\n",
        "        'a dog live in the hut',\n",
        "        'hut is dog home'\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(docs)\n",
        "print('Vocabulary:', list(vectorizer.vocabulary_.keys()),'\\n')\n",
        "print('N/n:', vectorizer.idf_, '\\n')\n",
        "print('idf = lg(N/n):', vectorizer.vocabulary_, '\\n')\n",
        "vector = vectorizer.transform([docs[0]])\n",
        "print(vector.toarray())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary: ['dog', 'live', 'in', 'home', 'the', 'hut', 'is'] \n",
            "\n",
            "N/n: [1.         1.28768207 1.28768207 1.28768207 1.69314718 1.28768207\n",
            " 1.69314718] \n",
            "\n",
            "idf = lg(N/n): {'dog': 0, 'live': 5, 'in': 3, 'home': 1, 'the': 6, 'hut': 2, 'is': 4} \n",
            "\n",
            "[[0.40912286 0.52682017 0.         0.52682017 0.         0.52682017\n",
            "  0.        ]]\n"
          ]
        }
      ]
    }
  ]
}