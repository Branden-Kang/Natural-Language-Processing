{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKGMn3/pPQxLztoqKvA3So"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://admantium.medium.com/python-nlp-libary-nltk-5fbc6166b48a)"
      ],
      "metadata": {
        "id": "fatFJajoM0x1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQUWab6gMzTB",
        "outputId": "a0c9e342-7d43-4d67-b0f7-ccaeb95d85e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('reuters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YDImwHxM4JC",
        "outputId": "20c7baf8-f4af-4b7c-a2d1-aee59ace0842"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "k9wOWowgM7uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Source: Wikipedia, Artificial Intelligence, https://en.wikipedia.org/wiki/Artificial_intelligence\n",
        "paragraph = '''Artificial intelligence was founded as an academic discipline in 1956, and in the years since it has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success, and renewed funding. AI research has tried and discarded many different approaches, including simulating the brain, modeling human problem solving, formal logic, large databases of knowledge, and imitating animal behavior. In the first decades of the 21st century, highly mathematical and statistical machine learning has dominated the field, and this technique has proved highly successful, helping to solve many challenging problems throughout industry and academia.'''\n",
        "sentences = []\n",
        "\n",
        "for sent in sent_tokenize(paragraph):\n",
        "  sentences.append(word_tokenize(sent))\n",
        "\n",
        "sentences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NALN7VzRM5Ha",
        "outputId": "ce256c8b-b54d-4b05-d281-4f688c96208f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Artificial',\n",
              " 'intelligence',\n",
              " 'was',\n",
              " 'founded',\n",
              " 'as',\n",
              " 'an',\n",
              " 'academic',\n",
              " 'discipline',\n",
              " 'in',\n",
              " '1956',\n",
              " ',',\n",
              " 'and',\n",
              " 'in',\n",
              " 'the',\n",
              " 'years',\n",
              " 'since',\n",
              " 'it',\n",
              " 'has',\n",
              " 'experienced',\n",
              " 'several',\n",
              " 'waves',\n",
              " 'of',\n",
              " 'optimism',\n",
              " ',',\n",
              " 'followed',\n",
              " 'by',\n",
              " 'disappointment',\n",
              " 'and',\n",
              " 'the',\n",
              " 'loss',\n",
              " 'of',\n",
              " 'funding',\n",
              " '(',\n",
              " 'known',\n",
              " 'as',\n",
              " 'an',\n",
              " '``',\n",
              " 'AI',\n",
              " 'winter',\n",
              " \"''\",\n",
              " ')',\n",
              " ',',\n",
              " 'followed',\n",
              " 'by',\n",
              " 'new',\n",
              " 'approaches',\n",
              " ',',\n",
              " 'success',\n",
              " ',',\n",
              " 'and',\n",
              " 'renewed',\n",
              " 'funding',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming and Lemmatization"
      ],
      "metadata": {
        "id": "oYW8Rw6KM-tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "sent = 'Artificial intelligence was founded as an academic discipline in 1956, and in the years since it has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success, and renewed funding.'\n",
        "stemmer = LancasterStemmer()\n",
        "stemmed_sent = [stemmer.stem(word) for word in word_tokenize(sent)]\n",
        "\n",
        "print(stemmed_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXUnO5vWM955",
        "outputId": "b6472980-a2e8-40d9-d7a9-78a0fff67600"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['art', 'intellig', 'was', 'found', 'as', 'an', 'academ', 'disciplin', 'in', '1956', ',', 'and', 'in', 'the', 'year', 'sint', 'it', 'has', 'expery', 'sev', 'wav', 'of', 'optim', ',', 'follow', 'by', 'disappoint', 'and', 'the', 'loss', 'of', 'fund', '(', 'known', 'as', 'an', '``', 'ai', 'wint', \"''\", ')', ',', 'follow', 'by', 'new', 'approach', ',', 'success', ',', 'and', 'renew', 'fund', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "sent = 'Artificial intelligence was founded as an academic discipline in 1956, and in the years since it has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success, and renewed funding.'\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmas = [lemmatizer.lemmatize(word) for word in word_tokenize(sent)]\n",
        "\n",
        "print(lemmas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6N8H590NB_3",
        "outputId": "b9d91848-ddf3-4782-c963-eac28b81b48d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Artificial', 'intelligence', 'wa', 'founded', 'a', 'an', 'academic', 'discipline', 'in', '1956', ',', 'and', 'in', 'the', 'year', 'since', 'it', 'ha', 'experienced', 'several', 'wave', 'of', 'optimism', ',', 'followed', 'by', 'disappointment', 'and', 'the', 'loss', 'of', 'funding', '(', 'known', 'a', 'an', '``', 'AI', 'winter', \"''\", ')', ',', 'followed', 'by', 'new', 'approach', ',', 'success', ',', 'and', 'renewed', 'funding', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part-of-Speech Tagging"
      ],
      "metadata": {
        "id": "m-FBUn_vXpG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "sent = 'Artificial intelligence was founded as an academic discipline in 1956, and in the years since it has experienced several waves of optimism, followed by disappointment and the loss of funding (known as an \"AI winter\"), followed by new approaches, success, and renewed funding.'\n",
        "pos_tag(sentences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fX6Brc4GNCQI",
        "outputId": "c25b5197-df02-47fe-ceda-37a60b37bb2a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Artificial', 'JJ'),\n",
              " ('intelligence', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('founded', 'VBN'),\n",
              " ('as', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('academic', 'JJ'),\n",
              " ('discipline', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('1956', 'CD'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('years', 'NNS'),\n",
              " ('since', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('has', 'VBZ'),\n",
              " ('experienced', 'VBN'),\n",
              " ('several', 'JJ'),\n",
              " ('waves', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('optimism', 'NN'),\n",
              " (',', ','),\n",
              " ('followed', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('disappointment', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('loss', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('funding', 'NN'),\n",
              " ('(', '('),\n",
              " ('known', 'VBN'),\n",
              " ('as', 'IN'),\n",
              " ('an', 'DT'),\n",
              " ('``', '``'),\n",
              " ('AI', 'NNP'),\n",
              " ('winter', 'NN'),\n",
              " (\"''\", \"''\"),\n",
              " (')', ')'),\n",
              " (',', ','),\n",
              " ('followed', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('new', 'JJ'),\n",
              " ('approaches', 'NNS'),\n",
              " (',', ','),\n",
              " ('success', 'NN'),\n",
              " (',', ','),\n",
              " ('and', 'CC'),\n",
              " ('renewed', 'VBN'),\n",
              " ('funding', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition"
      ],
      "metadata": {
        "id": "g2gdxIvIXt_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3_7JGBwXsSF",
        "outputId": "603de103-2da2-46b0-e388-e27d21b33256"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Source: Wikipedia, Artificial Intelligence, https://en.wikipedia.org/wiki/Artificial_intelligence\n",
        "sentence= '''\n",
        "In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.\n",
        "'''\n",
        "\n",
        "tagged_sentence = nltk.pos_tag(word_tokenize(sentence))\n",
        "tagged_sentence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwwgFlAkX01W",
        "outputId": "e181d134-f5a7-45cb-eb2d-03c6aff23011"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('In', 'IN'),\n",
              " ('2011', 'CD'),\n",
              " (',', ','),\n",
              " ('in', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('Jeopardy', 'NN'),\n",
              " ('!', '.'),\n",
              " ('quiz', 'NN'),\n",
              " ('show', 'NN'),\n",
              " ('exhibition', 'NN'),\n",
              " ('match', 'NN'),\n",
              " (',', ','),\n",
              " ('IBM', 'NNP'),\n",
              " (\"'s\", 'POS'),\n",
              " ('question', 'NN'),\n",
              " ('answering', 'NN'),\n",
              " ('system', 'NN'),\n",
              " (',', ','),\n",
              " ('Watson', 'NNP'),\n",
              " (',', ','),\n",
              " ('defeated', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('two', 'CD'),\n",
              " ('greatest', 'JJS'),\n",
              " ('Jeopardy', 'NN'),\n",
              " ('!', '.'),\n",
              " ('champions', 'NNS'),\n",
              " (',', ','),\n",
              " ('Brad', 'NNP'),\n",
              " ('Rutter', 'NNP'),\n",
              " ('and', 'CC'),\n",
              " ('Ken', 'NNP'),\n",
              " ('Jennings', 'NNP'),\n",
              " (',', ','),\n",
              " ('by', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('significant', 'JJ'),\n",
              " ('margin', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(nltk.ne_chunk(tagged_sentence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLiGf8JwX2tw",
        "outputId": "a347fd60-a2c8-4ea3-9b59-a94f227e3f63"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  In/IN\n",
            "  2011/CD\n",
            "  ,/,\n",
            "  in/IN\n",
            "  a/DT\n",
            "  Jeopardy/NN\n",
            "  !/.\n",
            "  quiz/NN\n",
            "  show/NN\n",
            "  exhibition/NN\n",
            "  match/NN\n",
            "  ,/,\n",
            "  (ORGANIZATION IBM/NNP)\n",
            "  's/POS\n",
            "  question/NN\n",
            "  answering/NN\n",
            "  system/NN\n",
            "  ,/,\n",
            "  (PERSON Watson/NNP)\n",
            "  ,/,\n",
            "  defeated/VBD\n",
            "  the/DT\n",
            "  two/CD\n",
            "  greatest/JJS\n",
            "  Jeopardy/NN\n",
            "  !/.\n",
            "  champions/NNS\n",
            "  ,/,\n",
            "  (PERSON Brad/NNP Rutter/NNP)\n",
            "  and/CC\n",
            "  (PERSON Ken/NNP Jennings/NNP)\n",
            "  ,/,\n",
            "  by/IN\n",
            "  a/DT\n",
            "  significant/JJ\n",
            "  margin/NN\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "lY5McNQmY-8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import reuters\n",
        "\n",
        "print(reuters.categories()[:10])\n",
        "#['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee']\n",
        "\n",
        "print(reuters.fileids()[:10])\n",
        "# ['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843']\n",
        "\n",
        "sample = 'test/14829'\n",
        "categories = reuters.categories(sample)\n",
        "\n",
        "print(categories)\n",
        "# ['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee']\n",
        "\n",
        "content = \"\"\n",
        "with reuters.open(sample) as stream:\n",
        "    content = stream.read()\n",
        "\n",
        "print(f\"Categories #{categories} / file #{sample}\")\n",
        "# Categories #['crude', 'nat-gas'] / file #test/14829\n",
        "\n",
        "print(f\"Content:\\#{content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS9AYo-aX4fu",
        "outputId": "1a578b7c-a16a-439c-d013-9da897d1ebc4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee']\n",
            "['test/14826', 'test/14828', 'test/14829', 'test/14832', 'test/14833', 'test/14839', 'test/14840', 'test/14841', 'test/14842', 'test/14843']\n",
            "['crude', 'nat-gas']\n",
            "Categories #['crude', 'nat-gas'] / file #test/14829\n",
            "Content:\\#JAPAN TO REVISE LONG-TERM ENERGY DEMAND DOWNWARDS\n",
            "  The Ministry of International Trade and\n",
            "  Industry (MITI) will revise its long-term energy supply/demand\n",
            "  outlook by August to meet a forecast downtrend in Japanese\n",
            "  energy demand, ministry officials said.\n",
            "      MITI is expected to lower the projection for primary energy\n",
            "  supplies in the year 2000 to 550 mln kilolitres (kl) from 600\n",
            "  mln, they said.\n",
            "      The decision follows the emergence of structural changes in\n",
            "  Japanese industry following the rise in the value of the yen\n",
            "  and a decline in domestic electric power demand.\n",
            "      MITI is planning to work out a revised energy supply/demand\n",
            "  outlook through deliberations of committee meetings of the\n",
            "  Agency of Natural Resources and Energy, the officials said.\n",
            "      They said MITI will also review the breakdown of energy\n",
            "  supply sources, including oil, nuclear, coal and natural gas.\n",
            "      Nuclear energy provided the bulk of Japan's electric power\n",
            "  in the fiscal year ended March 31, supplying an estimated 27\n",
            "  pct on a kilowatt/hour basis, followed by oil (23 pct) and\n",
            "  liquefied natural gas (21 pct), they noted.\n",
            "  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Corpus Management"
      ],
      "metadata": {
        "id": "lM0yXKs7ZBB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from  nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "\n",
        "corpus = PlaintextCorpusReader('wikipedia_articles', r'.*\\.txt')\n",
        "\n",
        "print(corpus.fileids())\n",
        "print(corpus.sents())"
      ],
      "metadata": {
        "id": "nYvr9G7UY_Uj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "from nltk.text import TextCollection\n",
        "\n",
        "corpus = PlaintextCorpusReader('wikipedia_articles', r'.*\\.txt')\n",
        "col = TextCollection(corpus.sents())\n",
        "print(col.count('the'))\n",
        "# 973\n",
        "print(col.common_contexts(['intelligence']))"
      ],
      "metadata": {
        "id": "1r3nEsp8ZDkq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from  nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
        "corpus = PlaintextCorpusReader('wikipedia_articles', r'.*\\.txt')\n",
        "\n",
        "vocab = nltk.FreqDist(w.lower() for w in corpus.words())\n",
        "#  FreqDist({'the': 65590, ',': 63310, '.': 52247, 'of': 39000, 'and': 30868, 'a': 30130, 'to': 27881, 'in': 24501, '-': 19867, '(': 18243, ...})\n",
        "all_words = nltk.FreqDist(w.lower() for w in corpus.words())\n",
        "word_features = list(all_words)"
      ],
      "metadata": {
        "id": "wLyMB_Z3ZIKJ"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}