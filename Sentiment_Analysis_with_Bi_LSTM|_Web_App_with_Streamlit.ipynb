{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis with Bi-LSTM| Web App with Streamlit.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLOZYml9Odk2/Wn9LOGTKi"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm9BEPuwSicJ",
        "colab_type": "text"
      },
      "source": [
        "[Reference](https://levelup.gitconnected.com/sentiment-analysis-642b935ab6f9)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpC2DfGOoj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Install Kaggle library\n",
        "# !pip install -q kaggle\n",
        "\n",
        "# #upload the kaggle.json file you downloaded\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # make a diectoryin which kajggle.json is stored\n",
        "# !mkdir ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# #download the dataset into the colab(paste API command after !)\n",
        "# !kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
        "\n",
        "# #unzip the data\n",
        "# !unzip imdb-dataset-of-50k-movie-reviews.zip"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9sxJ9WuSUV1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "397ba67c-b941-4dd8-b8dc-7cc0e4c19726"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!pwd\n",
        "os.chdir('gdrive/My Drive/Colab Notebooks')\n",
        "!pwd"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content\n",
            "/content/gdrive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZewHv8eQaPa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Embedding, LSTM, Bidirectional,Flatten,Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYJs-n3MSsGG",
        "colab_type": "text"
      },
      "source": [
        "# Import and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRKwr7LbQdzp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "424e66d4-38f2-45aa-84a3-dd2b88e37699"
      },
      "source": [
        "def remove_special_chars(tweets): \n",
        "  # it unrolls the hashtags to normal words\n",
        " for remove in map(lambda r: re.compile(re.escape(r)), [\",\", \":\", \"\\\"\", \"=\", \"&\", \";\", \"%\", \"$\",\n",
        "                                                        \"@\", \"%\", \"^\", \"*\", \"(\", \")\", \"{\", \"}\",\n",
        "                                                        \"[\", \"]\", \"|\", \"/\", \"\\\\\", \">\", \"<\", \"-\",\n",
        "                                                        \"!\", \"?\", \".\", \"'\",\n",
        "                                                        \" — \", \" — -\", \"#\"]):\n",
        "   tweets.replace(remove, \"\", inplace=True)\n",
        "   return tweets\n",
        "\n",
        "def remove_tags(text):\n",
        "  return re.compile(r'<[^>]+>').sub('', text)\n",
        "\n",
        "def remove_num(text):\n",
        "  return ''.join(re.sub(r\"([0–9]+)\",\"\",text))\n",
        " \n",
        "data = pd.read_csv('IMDB Dataset.csv')\n",
        "data.review = data.review.apply(lambda x : remove_tags(x))\n",
        "data.review = data.review.apply(lambda x : remove_num(x))\n",
        "remove_special_chars(data.review)\n",
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. The filming tec...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. The filming tec...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tFG7yPqSnDn",
        "colab_type": "text"
      },
      "source": [
        "# Word Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LIpB2WwQmNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words=5000,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n",
        "\n",
        "tokenizer.fit_on_texts(data['review'])\n",
        "X = tokenizer.texts_to_sequences(data['review'])\n",
        "X = pad_sequences(X,maxlen=500)\n",
        "Y = data['sentiment']\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# We can then create our train and test sets:\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state = 24)\n",
        "\n",
        "#We store this tokenizer in a file to use later in web app\n",
        "import pickle\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "def prepare_targets(y_train, y_test):\n",
        "  le = LabelEncoder()\n",
        "  le.fit(y_train)\n",
        "  y_train_enc = le.transform(y_train)\n",
        "  y_test_enc = le.transform(y_test)\n",
        "  return y_train_enc, y_test_enc\n",
        " \n",
        "ytrain,ytest = prepare_targets(Y_train,Y_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zENRnfzT1Sx",
        "colab_type": "text"
      },
      "source": [
        "# Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHXMBMxjTQp7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d9901e35-09e0-44a3-818a-68f03078aaf1"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=500))\n",
        "model.add(Bidirectional(LSTM(128)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        " loss='binary_crossentropy',\n",
        " metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 50)           6585300   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 256)               183296    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 6,768,853\n",
            "Trainable params: 6,768,853\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ac9t5qAUAP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "f2a5bd20-2dab-40b6-a2e1-ce380141d4fa"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "history=model.fit(X_train, ytrain,\n",
        " batch_size=128,\n",
        " epochs=20,\n",
        " validation_data=[X_test, ytest],\n",
        " callbacks=[es])\n",
        "\n",
        "#We save this model so that we can use in own web app\n",
        "model.save('movie_sent.h5')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "274/274 [==============================] - 800s 3s/step - loss: 0.4611 - accuracy: 0.7727 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "274/274 [==============================] - 787s 3s/step - loss: 0.2740 - accuracy: 0.8933 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "274/274 [==============================] - 775s 3s/step - loss: 0.2393 - accuracy: 0.9079 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "274/274 [==============================] - 774s 3s/step - loss: 0.2147 - accuracy: 0.9176 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "274/274 [==============================] - 772s 3s/step - loss: 0.1874 - accuracy: 0.9289 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "274/274 [==============================] - 782s 3s/step - loss: 0.1946 - accuracy: 0.9253 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0yxJFzcUJ7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b987db8d-3365-4f23-f94e-a30cad00ee37"
      },
      "source": [
        "string11='''Between the Lovecraftian overtones and Liberato’s performance, \n",
        "The Beach House offers up beautifully shot terror and will make you think before opening your door.'''\n",
        "x_1=tokenizer.texts_to_sequences([string11])\n",
        "x_1 = pad_sequences(x_1,maxlen=500)\n",
        "model.predict(x_1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.93133926]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X34WwrScUTPC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0796eab-2229-4832-faeb-efd90bf7892d"
      },
      "source": [
        "!streamlit run sent_anaysis.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: streamlit: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}