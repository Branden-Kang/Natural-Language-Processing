{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StanfordNLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOnE9JFmM1Ac3/9jdRs0hBr"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NQM0BDX1BP-",
        "colab_type": "text"
      },
      "source": [
        "# StanfordNLP\n",
        "- [Reference](https://medium.com/analytics-vidhya/introduction-to-stanfordnlp-an-nlp-library-for-53-languages-with-python-code-d7c3efdca118)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I23Fdmd0e9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "a0257b50-ee03-47da-f0ac-9370e5db2fc0"
      },
      "source": [
        "!pip install stanfordnlp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stanfordnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/bf/5d2898febb6e993fcccd90484cba3c46353658511a41430012e901824e94/stanfordnlp-0.2.0-py3-none-any.whl (158kB)\n",
            "\r\u001b[K     |██                              | 10kB 29.2MB/s eta 0:00:01\r\u001b[K     |████▏                           | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 81kB 9.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanfordnlp) (2.23.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (47.3.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanfordnlp) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->stanfordnlp) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanfordnlp) (3.0.4)\n",
            "Installing collected packages: stanfordnlp\n",
            "Successfully installed stanfordnlp-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnba_RfM0lqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import stanfordnlp"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STegHcGN0nA_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "c4a091b4-b8c8-4d7c-82bb-f5ee2baf107b"
      },
      "source": [
        "stanfordnlp.download('en')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"en_ewt\" for language \"en\".\n",
            "Would you like to download the models for: en_ewt now? (Y/n)\n",
            "Y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: en_ewt\n",
            "Download location: /root/stanfordnlp_resources/en_ewt_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 235M/235M [00:14<00:00, 16.5MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/en_ewt_models.zip\n",
            "Extracting models file for: en_ewt\n",
            "Cleaning up...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLmSh7na0oJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "d5d91103-80ad-447b-9045-c6b770275fe6"
      },
      "source": [
        "!pip freeze | grep torch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch==1.5.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRNs0Tlx07jA",
        "colab_type": "text"
      },
      "source": [
        "# Using StanfordNLP to Perform Basic NLP Tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSN2lA170tsv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "8f1bfc01-a5f9-4475-e59c-d6d4ef2e9e5b"
      },
      "source": [
        "nlp = stanfordnlp.Pipeline(processors = \"tokenize,mwt,lemma,pos\")\n",
        "doc = nlp(\"\"\"The prospects for Britain’s orderly withdrawal from the European Union on March 29 have receded further, even as MPs rallied to stop a no-deal scenario. An amendment to the draft bill on the termination of London’s membership of the bloc obliges Prime Minister Theresa May to renegotiate her withdrawal agreement with Brussels. A Tory backbencher’s proposal calls on the government to come up with alternatives to the Irish backstop, a central tenet of the deal Britain agreed with the rest of the EU.\"\"\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use device: gpu\n",
            "---\n",
            "Loading: tokenize\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "---\n",
            "Loading: lemma\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Building an attentional Seq2Seq model...\n",
            "Using a Bi-LSTM encoder\n",
            "Using soft attention for LSTM.\n",
            "Finetune all embeddings.\n",
            "[Running seq2seq lemmatizer with edit classifier]\n",
            "---\n",
            "Loading: pos\n",
            "With settings: \n",
            "{'model_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/root/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
            "Done loading processors!\n",
            "---\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOuG6qAe1Zv3",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFysCVXU1UqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "2022e4aa-860f-4d71-e1fd-407092791c89"
      },
      "source": [
        "doc.sentences[0].print_tokens()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Token index=1;words=[<Word index=1;text=The;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art>]>\n",
            "<Token index=2;words=[<Word index=2;text=prospects;lemma=prospect;upos=NOUN;xpos=NNS;feats=Number=Plur>]>\n",
            "<Token index=3;words=[<Word index=3;text=for;lemma=for;upos=ADP;xpos=IN;feats=_>]>\n",
            "<Token index=4;words=[<Word index=4;text=Britain;lemma=Britain;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
            "<Token index=5;words=[<Word index=5;text=’s;lemma='s;upos=PART;xpos=POS;feats=_>]>\n",
            "<Token index=6;words=[<Word index=6;text=orderly;lemma=orderly;upos=ADJ;xpos=JJ;feats=Degree=Pos>]>\n",
            "<Token index=7;words=[<Word index=7;text=withdrawal;lemma=withdrawal;upos=NOUN;xpos=NN;feats=Number=Sing>]>\n",
            "<Token index=8;words=[<Word index=8;text=from;lemma=from;upos=ADP;xpos=IN;feats=_>]>\n",
            "<Token index=9;words=[<Word index=9;text=the;lemma=the;upos=DET;xpos=DT;feats=Definite=Def|PronType=Art>]>\n",
            "<Token index=10;words=[<Word index=10;text=European;lemma=european;upos=ADJ;xpos=JJ;feats=Degree=Pos>]>\n",
            "<Token index=11;words=[<Word index=11;text=Union;lemma=union;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
            "<Token index=12;words=[<Word index=12;text=on;lemma=on;upos=ADP;xpos=IN;feats=_>]>\n",
            "<Token index=13;words=[<Word index=13;text=March;lemma=March;upos=PROPN;xpos=NNP;feats=Number=Sing>]>\n",
            "<Token index=14;words=[<Word index=14;text=29;lemma=29;upos=NUM;xpos=CD;feats=NumType=Card>]>\n",
            "<Token index=15;words=[<Word index=15;text=have;lemma=have;upos=AUX;xpos=VBP;feats=Mood=Ind|Tense=Pres|VerbForm=Fin>]>\n",
            "<Token index=16;words=[<Word index=16;text=receded;lemma=recede;upos=VERB;xpos=VBN;feats=Tense=Past|VerbForm=Part>]>\n",
            "<Token index=17;words=[<Word index=17;text=further;lemma=further;upos=ADV;xpos=RB;feats=_>]>\n",
            "<Token index=18;words=[<Word index=18;text=,;lemma=,;upos=PUNCT;xpos=,;feats=_>]>\n",
            "<Token index=19;words=[<Word index=19;text=even;lemma=even;upos=ADV;xpos=RB;feats=_>]>\n",
            "<Token index=20;words=[<Word index=20;text=as;lemma=as;upos=SCONJ;xpos=IN;feats=_>]>\n",
            "<Token index=21;words=[<Word index=21;text=MPs;lemma=mps;upos=PROPN;xpos=NNPS;feats=Number=Plur>]>\n",
            "<Token index=22;words=[<Word index=22;text=rallied;lemma=rally;upos=VERB;xpos=VBD;feats=Mood=Ind|Tense=Past|VerbForm=Fin>]>\n",
            "<Token index=23;words=[<Word index=23;text=to;lemma=to;upos=PART;xpos=TO;feats=_>]>\n",
            "<Token index=24;words=[<Word index=24;text=stop;lemma=stop;upos=VERB;xpos=VB;feats=VerbForm=Inf>]>\n",
            "<Token index=25;words=[<Word index=25;text=a;lemma=a;upos=DET;xpos=DT;feats=Definite=Ind|PronType=Art>]>\n",
            "<Token index=26;words=[<Word index=26;text=no-deal;lemma=no-deal;upos=ADJ;xpos=JJ;feats=Degree=Pos>]>\n",
            "<Token index=27;words=[<Word index=27;text=scenario;lemma=scenario;upos=NOUN;xpos=NN;feats=Number=Sing>]>\n",
            "<Token index=28;words=[<Word index=28;text=.;lemma=.;upos=PUNCT;xpos=.;feats=_>]>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQeHX1SW1hca",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOK-qXIA1dT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1111c11f-9d21-45db-f486-dc9655c96817"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def extract_lemma(doc):\n",
        "    parsed_text = {'word':[], 'lemma':[]}\n",
        "    for sent in doc.sentences:\n",
        "        for wrd in sent.words:\n",
        "            #extract text and lemma\n",
        "            parsed_text['word'].append(wrd.text)\n",
        "            parsed_text['lemma'].append(wrd.lemma)\n",
        "    #return a dataframe\n",
        "    return pd.DataFrame(parsed_text)\n",
        "extract_lemma(doc)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prospects</td>\n",
              "      <td>prospect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>for</td>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Britain</td>\n",
              "      <td>Britain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>’s</td>\n",
              "      <td>'s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>rest</td>\n",
              "      <td>rest</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>of</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>EU</td>\n",
              "      <td>EU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         word     lemma\n",
              "0         The       the\n",
              "1   prospects  prospect\n",
              "2         for       for\n",
              "3     Britain   Britain\n",
              "4          ’s        's\n",
              "..        ...       ...\n",
              "86       rest      rest\n",
              "87         of        of\n",
              "88        the       the\n",
              "89         EU        EU\n",
              "90          .         .\n",
              "\n",
              "[91 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQ_17dFD1qz8",
        "colab_type": "text"
      },
      "source": [
        "## Parts of Speech (PoS) Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St7WUOOg1ncq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5212abfb-0a9e-4be7-f51a-73191751a14e"
      },
      "source": [
        "#dictionary to hold pos tags and their explanations\n",
        "pos_dict = {\n",
        "'CC': 'coordinating conjunction',\n",
        "'CD': 'cardinal digit',\n",
        "'DT': 'determiner',\n",
        "'EX': 'existential there (like: \\\"there is\\\" ... think of it like \\\"there exists\\\")',\n",
        "'FW': 'foreign word',\n",
        "'IN':  'preposition/subordinating conjunction',\n",
        "'JJ': 'adjective \\'big\\'',\n",
        "'JJR': 'adjective, comparative \\'bigger\\'',\n",
        "'JJS': 'adjective, superlative \\'biggest\\'',\n",
        "'LS': 'list marker 1)',\n",
        "'MD': 'modal could, will',\n",
        "'NN': 'noun, singular \\'desk\\'',\n",
        "'NNS': 'noun plural \\'desks\\'',\n",
        "'NNP': 'proper noun, singular \\'Harrison\\'',\n",
        "'NNPS': 'proper noun, plural \\'Americans\\'',\n",
        "'PDT': 'predeterminer \\'all the kids\\'',\n",
        "'POS': 'possessive ending parent\\'s',\n",
        "'PRP': 'personal pronoun I, he, she',\n",
        "'PRP$': 'possessive pronoun my, his, hers',\n",
        "'RB': 'adverb very, silently,',\n",
        "'RBR': 'adverb, comparative better',\n",
        "'RBS': 'adverb, superlative best',\n",
        "'RP': 'particle give up',\n",
        "'TO': 'to go \\'to\\' the store.',\n",
        "'UH': 'interjection errrrrrrrm',\n",
        "'VB': 'verb, base form take',\n",
        "'VBD': 'verb, past tense took',\n",
        "'VBG': 'verb, gerund/present participle taking',\n",
        "'VBN': 'verb, past participle taken',\n",
        "'VBP': 'verb, sing. present, non-3d take',\n",
        "'VBZ': 'verb, 3rd person sing. present takes',\n",
        "'WDT': 'wh-determiner which',\n",
        "'WP': 'wh-pronoun who, what',\n",
        "'WP$': 'possessive wh-pronoun whose',\n",
        "'WRB': 'wh-abverb where, when',\n",
        "'QF' : 'quantifier, bahut, thoda, kam (Hindi)',\n",
        "'VM' : 'main verb',\n",
        "'PSP' : 'postposition, common in indian langs',\n",
        "'DEM' : 'demonstrative, common in indian langs'\n",
        "}\n",
        "\n",
        "def extract_pos(doc):\n",
        "    parsed_text = {'word':[], 'pos':[], 'exp':[]}\n",
        "    for sent in doc.sentences:\n",
        "        for wrd in sent.words:\n",
        "            if wrd.pos in pos_dict.keys():\n",
        "                pos_exp = pos_dict[wrd.pos]\n",
        "            else:\n",
        "                pos_exp = 'NA'\n",
        "            parsed_text['word'].append(wrd.text)\n",
        "            parsed_text['pos'].append(wrd.pos)\n",
        "            parsed_text['exp'].append(pos_exp)\n",
        "    return pd.DataFrame(parsed_text)\n",
        "\n",
        "extract_pos(doc)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>exp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The</td>\n",
              "      <td>DT</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>prospects</td>\n",
              "      <td>NNS</td>\n",
              "      <td>noun plural 'desks'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>for</td>\n",
              "      <td>IN</td>\n",
              "      <td>preposition/subordinating conjunction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Britain</td>\n",
              "      <td>NNP</td>\n",
              "      <td>proper noun, singular 'Harrison'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>’s</td>\n",
              "      <td>POS</td>\n",
              "      <td>possessive ending parent's</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>rest</td>\n",
              "      <td>NN</td>\n",
              "      <td>noun, singular 'desk'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>preposition/subordinating conjunction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>determiner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>EU</td>\n",
              "      <td>NNP</td>\n",
              "      <td>proper noun, singular 'Harrison'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>91 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         word  pos                                    exp\n",
              "0         The   DT                             determiner\n",
              "1   prospects  NNS                    noun plural 'desks'\n",
              "2         for   IN  preposition/subordinating conjunction\n",
              "3     Britain  NNP       proper noun, singular 'Harrison'\n",
              "4          ’s  POS             possessive ending parent's\n",
              "..        ...  ...                                    ...\n",
              "86       rest   NN                  noun, singular 'desk'\n",
              "87         of   IN  preposition/subordinating conjunction\n",
              "88        the   DT                             determiner\n",
              "89         EU  NNP       proper noun, singular 'Harrison'\n",
              "90          .    .                                     NA\n",
              "\n",
              "[91 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5LlW3Uo19fZ",
        "colab_type": "text"
      },
      "source": [
        "## Dependency Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWRA70wk16qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc.sentences[0].print_dependencies()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "actYVNlR2Ays",
        "colab_type": "text"
      },
      "source": [
        "# Implementing StanfordNLP on the Hindi Language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VURmMgER1_B5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5e88145d-334f-4e1e-814a-d85ff128b4db"
      },
      "source": [
        "stanfordnlp.download('hi')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the default treebank \"hi_hdtb\" for language \"hi\".\n",
            "Would you like to download the models for: hi_hdtb now? (Y/n)\n",
            "Y\n",
            "\n",
            "Default download directory: /root/stanfordnlp_resources\n",
            "Hit enter to continue or type an alternate directory.\n",
            "\n",
            "\n",
            "Downloading models for: hi_hdtb\n",
            "Download location: /root/stanfordnlp_resources/hi_hdtb_models.zip\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 208M/208M [00:20<00:00, 9.94MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Download complete.  Models saved to: /root/stanfordnlp_resources/hi_hdtb_models.zip\n",
            "Extracting models file for: hi_hdtb\n",
            "Cleaning up...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1svKATD2FeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hindi_doc = nlp(\"\"\"केंद्र की मोदी सरकार ने शुक्रवार को अपना अंतरिम बजट पेश किया. कार्यवाहक वित्त मंत्री पीयूष गोयल ने अपने बजट में किसान, मजदूर, करदाता, महिला वर्ग समेत हर किसी के लिए बंपर ऐलान किए. हालांकि, बजट के बाद भी टैक्स को लेकर काफी कन्फ्यूजन बना रहा. केंद्र सरकार के इस अंतरिम बजट क्या खास रहा और किसको क्या मिला, आसान भाषा में यहां समझें\"\"\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bv_pblHY2NV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "576b61c4-20be-41e5-f33a-4c6d3ed06c80"
      },
      "source": [
        "extract_pos(hindi_doc)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>pos</th>\n",
              "      <th>exp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>केंद्र</td>\n",
              "      <td>GW</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>की</td>\n",
              "      <td>FW</td>\n",
              "      <td>foreign word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>मोदी</td>\n",
              "      <td>AFX</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>सरकार</td>\n",
              "      <td>AFX</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ने</td>\n",
              "      <td>AFX</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>आसान</td>\n",
              "      <td>GW</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>भाषा</td>\n",
              "      <td>GW</td>\n",
              "      <td>NA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>में</td>\n",
              "      <td>FW</td>\n",
              "      <td>foreign word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>यहां</td>\n",
              "      <td>NN</td>\n",
              "      <td>noun, singular 'desk'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>समझें</td>\n",
              "      <td>NN</td>\n",
              "      <td>noun, singular 'desk'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      word  pos                    exp\n",
              "0   केंद्र   GW                     NA\n",
              "1       की   FW           foreign word\n",
              "2     मोदी  AFX                     NA\n",
              "3    सरकार  AFX                     NA\n",
              "4       ने  AFX                     NA\n",
              "..     ...  ...                    ...\n",
              "67    आसान   GW                     NA\n",
              "68    भाषा   GW                     NA\n",
              "69     में   FW           foreign word\n",
              "70    यहां   NN  noun, singular 'desk'\n",
              "71   समझें   NN  noun, singular 'desk'\n",
              "\n",
              "[72 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    }
  ]
}