{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPARlF5Q6+TEXNVJnXCySyO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://www.kaggle.com/code/shubham0204/tweet-classification-with-mlp-mixers-tf-keras)"
      ],
      "metadata": {
        "id": "p_QX5shVnxYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In 2021, Google introduced MLP-Mixer 11, an architecture based on Multilayer perceptrons ( MLPs ) and Mixer layers. Each Mixer layer consists of two MLPs, one for token-mixing ( mixing per-location features ) and another for channel-mixing ( mixing spatial information ).\n",
        "This architecture yields competitive results against models which use convolutions and vision transformers.\n",
        "\n",
        "Using a similar approach, I've tried using MLP Mixers for text classification, thereby using them on embeddings of shape max_length * embedding_dims. The architecture is similar to what is mentioned in the paper, except for some changes in how the text sequences are fed to the Mixer layers."
      ],
      "metadata": {
        "id": "woHVeKLhj-x2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Processing the text data"
      ],
      "metadata": {
        "id": "zQUNyxYclIPz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.a. Reading and truncating the CSV data"
      ],
      "metadata": {
        "id": "JEijKHwAlLX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_58ITeQQSS5",
        "outputId": "ac52c11a-7fe2-497b-96a5-ecba31c0f8df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Importing the required packages.\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the CSV file using Pandas\n",
        "df = pd.read_csv( 'https://raw.githubusercontent.com/nikjohn7/Disaster-Tweets-Kaggle/main/data/train.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EFONqIejRIyu",
        "outputId": "d2a64d47-1996-406f-a3a8-0b9033d5388e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-a3ad4f51-09b1-44d5-9483-3223ce8ee46b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3ad4f51-09b1-44d5-9483-3223ce8ee46b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-361fbef5-4ba4-4340-8f47-b224156cb7ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-361fbef5-4ba4-4340-8f47-b224156cb7ad')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-361fbef5-4ba4-4340-8f47-b224156cb7ad button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3ad4f51-09b1-44d5-9483-3223ce8ee46b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3ad4f51-09b1-44d5-9483-3223ce8ee46b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Truncate the dataFrame and use only `text` and `target` columns.\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/nikjohn7/Disaster-Tweets-Kaggle/main/data/train.csv', usecols=[ 'text' , 'target' ] )\n",
        "print( df.head() )\n",
        "\n",
        "# Store the entries in the above mentioned columns in NumPy arrays.\n",
        "raw_texts = df[ 'text' ].values\n",
        "raw_labels = df[ 'target' ].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67yHLrbQRL5K",
        "outputId": "683fe370-ae90-427a-c68d-8f4a60c33230"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  target\n",
            "0  Our Deeds are the Reason of this #earthquake M...       1\n",
            "1             Forest fire near La Ronge Sask. Canada       1\n",
            "2  All residents asked to 'shelter in place' are ...       1\n",
            "3  13,000 people receive #wildfires evacuation or...       1\n",
            "4  Just got sent this photo from Ruby #Alaska as ...       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the no. of samples for each class.\n",
        "print(df[ 'target' ].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4URG1L3CRSfB",
        "outputId": "f199fd0f-d211-48d9-8397-b2e64e296b1e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    4342\n",
            "1    3271\n",
            "Name: target, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight= 'balanced', classes=np.unique(raw_labels), y=raw_labels)\n",
        "print(class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhx7Wf8VRmVx",
        "outputId": "495ecd56-4b05-4231-ff9c-ab2de084e797"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.87666974 1.1637114 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = dict(zip(np.unique(raw_labels), class_weights))\n",
        "print(class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxCkdbWeRVaV",
        "outputId": "6248047a-323b-4298-f06d-be0e31be6049"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.8766697374481806, 1: 1.1637114032405993}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.b. Cleaning and tokenizing the textual data"
      ],
      "metadata": {
        "id": "2Rz-WOMjlcob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regex to remove non-alphabet characters\\\n",
        "r1 = re.compile( '[^a-zA-Z ]' )\n",
        "\n",
        "# Regex to remove hyperlinks ( \"https://...\" )\n",
        "r2 = re.compile( 'http://\\S+|https://\\S+' )\n",
        "\n",
        "# Regex to extract words starting with #\n",
        "r3 = re.compile( '#(\\w+)' )\n",
        "\n",
        "# Remove non-alphabet char from given sentence. See https://stackoverflow.com/questions/22520932/python-remove-all-non-alphabet-chars-from-string\n",
        "def remove_non_alphabet_char( sent ):\n",
        "    return r1.sub( '' , sent )\n",
        "\n",
        "# Remove hyperlinks from given sentence. See https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python/11332580\n",
        "def remove_links( sent ):\n",
        "    return r2.sub( '' , sent )\n",
        "\n",
        "# Remove emojis. See https://stackoverflow.com/a/33417311/10878733\n",
        "def remove_emojis( sent ):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"\n",
        "        u\"\\U0001F300-\\U0001F5FF\"\n",
        "        u\"\\U0001F680-\\U0001F6FF\"\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub( r'',sent )\n",
        "\n",
        "\n",
        "# Clean the given sentence ( using the two methods above ) and tokenize it.\n",
        "# Also, remove stop words from the sentence.\n",
        "def process_sent( sent ):\n",
        "    sent = text.lower()\n",
        "    sent = remove_links( sent )\n",
        "    sent = remove_non_alphabet_char( sent )\n",
        "    sent = remove_emojis( sent )\n",
        "    tokens = sent.split()\n",
        "    tokens = [ token.strip() for token in tokens if token not in stopwords.words( 'english' ) ]\n",
        "    return tokens\n",
        "\n",
        "# Collect tokens and tokenized sentences in two arrays.\n",
        "processed_tokens = []\n",
        "tokenized_sentences = []\n",
        "for text in raw_texts:\n",
        "    tokens = process_sent( text )\n",
        "    processed_tokens += tokens\n",
        "    tokenized_sentences.append( tokens )\n",
        "\n",
        "# Get unique tokens\n",
        "unique_tokens = list( set( processed_tokens ) )\n",
        "unique_tokens = np.array( unique_tokens )\n",
        "\n",
        "# Compute vocabulary size ( will be used for the Embedding layer )\n",
        "vocab_size = len( unique_tokens )\n",
        "# Create an array of indexed starting from 1 to vocab_size + 1\n",
        "# For ex. [ 1 , 2 , 3 , ... , vocab_size ]\n",
        "indices = np.arange( 1 , vocab_size + 1 )\n",
        "\n",
        "# Zip unique_tokens and indices to create a dict with elements ( index , token ) where index has dtype=int and\n",
        "# token has dtype=str\n",
        "# This dict maps every index to its corresponding token.\n",
        "int_to_word = dict( zip( indices , unique_tokens ) )\n",
        "\n",
        "# This dict maps every token to its corresponding index.\n",
        "word_to_int = dict( zip( unique_tokens , indices ) )"
      ],
      "metadata": {
        "id": "VteI1TOkSVjc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = max( [ len( arr ) for arr in tokenized_sentences ] )"
      ],
      "metadata": {
        "id": "u2MSomLWSchi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the given tokenized sentence to an integer sequence\n",
        "# For example, [ 'apple' , 'orange' ] --> [ 1023 , 1102]\n",
        "def sent_to_int_seq( sent ):\n",
        "    int_seq = [ word_to_int[ token ] if token in unique_tokens else 0 for token in sent ]\n",
        "    return int_seq\n",
        "\n",
        "# Pad the given integer sequence with zeros ( from the end of the sequences )\n",
        "# For example, if maxlen=5,\n",
        "# [ 56 , 78 ] -> [ 56 , 78 , 0 , 0 , 0 ]\n",
        "# [ 34 , 56 , 78 , 23 , 13 , 12 ] -> [ 34 , 56 , 78 , 23 , 13 ]\n",
        "def pad_sequence( seq , maxlen ):\n",
        "    out = np.zeros( shape=( maxlen , ) )\n",
        "    out[ 0 : len( seq ) ] = seq\n",
        "    return out\n",
        "\n",
        "# Compute the max length of the tokenized sentences.\n",
        "# Will be used for padding the sequences.\n",
        "maxlen = max( [ len( arr ) for arr in tokenized_sentences ] )\n",
        "print( f'Max Length for input sequences : {maxlen}')\n",
        "\n",
        "# Convert tokenized_sentences to integer sequences\n",
        "# Finally pad the integer sequence and store it in an array.\n",
        "padded_sentences = []\n",
        "for sent in tokenized_sentences:\n",
        "    padded_sentences.append( pad_sequence( sent_to_int_seq( sent ) , maxlen ) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ColB9OY0Spku",
        "outputId": "47cd1d96-2c41-47e7-b899-945b34aeeaeb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Length for input sequences : 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert list to ndarray\n",
        "x = np.array( padded_sentences )\n",
        "print( x.shape )\n",
        "\n",
        "# Reshape raw_labels from shape ( num_labels , ) to ( num_labels , 1 )\n",
        "#y = raw_labels.reshape( -1 , 1)\n",
        "y = tf.keras.utils.to_categorical( raw_labels , num_classes=2 )\n",
        "print( y.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLr_T8NlSrYr",
        "outputId": "36097da0-3402-4acc-fc9f-7234faa2d204"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7613, 23)\n",
            "(7613, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing datasets.\n",
        "train_x , test_x , train_y , test_y = sklearn.model_selection.train_test_split( x , y , test_size=0.2 )\n",
        "print( train_x.shape )\n",
        "print( train_y.shape )\n",
        "print( test_x.shape )\n",
        "print( test_y.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHEPKerrSssv",
        "outputId": "10f8da3f-9046-467c-8e89-684bbd82a034"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6090, 23)\n",
            "(6090, 2)\n",
            "(1523, 23)\n",
            "(1523, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Training the model\n",
        "\n",
        "MLP Mixer is designed originally for image classification problems, as observed in their research paper. We modify the architecture and produce patches from embeddings of shape ( num_patches , embedding_dims ). In context of textual data, embedding_dims could be thought as num_channels in an image.\n",
        "\n",
        "The rest of the components including MLPs and Mixer layers remain as they are."
      ],
      "metadata": {
        "id": "KiUlYbHznSu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multilayer Perceptron with GeLU ( Gaussian Linear Units ) activation\n",
        "def mlp( x , hidden_dims ):\n",
        "    y = tf.keras.layers.Dense( hidden_dims )( x )\n",
        "    y = tf.nn.gelu( y )\n",
        "    y = tf.keras.layers.Dense( x.shape[ -1 ] )( y )\n",
        "    y = tf.keras.layers.Dropout( 0.4 )( y )\n",
        "    return y\n",
        "\n",
        "# Token Mixing MLPs : Allow communication within tokens ( patches ) or, intuitively, between different parts\n",
        "# of the same sequence.\n",
        "def token_mixing( x , token_mixing_mlp_dims ):\n",
        "    # x is a tensor of shape ( batch_size , num_patches , channels )\n",
        "    x = tf.keras.layers.LayerNormalization( epsilon=1e-6 )( x )\n",
        "    x = tf.keras.layers.Permute( dims=[ 2 , 1 ] )( x )\n",
        "    # After transposition, shape of x -> ( batch_size , channels , num_patches )\n",
        "    x = mlp( x , token_mixing_mlp_dims )\n",
        "    return x\n",
        "\n",
        "# Channel Mixing MLPs : Allow communication within channels ( features of embeddings )\n",
        "def channel_mixing( x , channel_mixing_mlp_dims ):\n",
        "    # x is a tensor of shape ( batch_size , num_patches , channels )\n",
        "    x = tf.keras.layers.LayerNormalization( epsilon=1e-6 )( x )\n",
        "    x = mlp( x , channel_mixing_mlp_dims )\n",
        "    return x\n",
        "\n",
        "# Mixer layer consisting of token mixing MLPs and channel mixing MLPs\n",
        "# input shape -> ( batch_size , channels , num_patches )\n",
        "# output shape -> ( batch_size , channels , num_patches )\n",
        "def mixer( x , token_mixing_mlp_dims , channel_mixing_mlp_dims ):\n",
        "    # inputs x of are of shape ( batch_size , num_patches , channels )\n",
        "    # Note: \"channels\" is used instead of \"embedding_dims\"\n",
        "\n",
        "    # Add token mixing MLPs\n",
        "    token_mixing_out = token_mixing( x , token_mixing_mlp_dims )\n",
        "    # Shape of token_mixing_out -> ( batch_size , channels , num_patches )\n",
        "\n",
        "    token_mixing_out = tf.keras.layers.Permute( dims=[ 2 , 1 ] )( token_mixing_out )\n",
        "    # Shape of transposition -> ( batch_size , num_patches , channels )\n",
        "\n",
        "    #  Add skip connection\n",
        "    token_mixing_out = tf.keras.layers.Add()( [ x , token_mixing_out ] )\n",
        "\n",
        "    # Add channel mixing MLPs\n",
        "    channel_mixing_out = channel_mixing( token_mixing_out , channel_mixing_mlp_dims )\n",
        "    # Shape of channel_mixing_out -> ( batch_size , num_patches , channels )\n",
        "\n",
        "    # Add skip connection\n",
        "    channel_mixing_out = tf.keras.layers.Add()( [ channel_mixing_out , token_mixing_out ] )\n",
        "    # Shape of channel_mixing_out -> ( batch_size , num_patches , channels )\n",
        "\n",
        "    return channel_mixing_out"
      ],
      "metadata": {
        "id": "mUooFIavSy_J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These hyperparameters were searched with KerasTuner\n",
        "embedding_dims = 64\n",
        "token_mixing_mlp_dims = 32\n",
        "channel_mixing_mlp_dims = 64\n",
        "patch_size = 5\n",
        "num_mixer_layers = 8\n",
        "learning_rate = 5e-3\n",
        "\n",
        "num_classes = 2\n",
        "seq_input_shape = ( maxlen , )\n",
        "\n",
        "# Model input layer\n",
        "inputs = tf.keras.layers.Input( shape=seq_input_shape )\n",
        "\n",
        "# Embedding layer which converts int sequences into dense vectors\n",
        "embedding = tf.keras.layers.Embedding( input_dim=vocab_size + 1 , output_dim=embedding_dims , input_length=maxlen )( inputs )\n",
        "\n",
        "# Conv1D layer to produce patches from given sequences.\n",
        "patches = tf.keras.layers.Conv1D( embedding_dims ,\n",
        "                                 kernel_size=patch_size ,\n",
        "                                 strides=patch_size ,\n",
        "                                 use_bias=False ,\n",
        "                                 trainable=False )( embedding )\n",
        "\n",
        "x = patches\n",
        "for _ in range( num_mixer_layers ):\n",
        "    x = mixer( x , token_mixing_mlp_dims , channel_mixing_mlp_dims )\n",
        "\n",
        "x = tf.keras.layers.LayerNormalization( epsilon=1e-6 )( x )\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()( x )\n",
        "outputs = tf.keras.layers.Dense( num_classes , activation='softmax' )( x )\n",
        "\n",
        "model = tf.keras.models.Model( inputs , outputs )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8C0Tw67S0a_",
        "outputId": "1dfebdb2-81dc-4d34-a2ba-3a8bcbdad112"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 23)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 23, 64)       1086208     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4, 64)        20480       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization (LayerNorm  (None, 4, 64)       128         ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " permute (Permute)              (None, 64, 4)        0           ['layer_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 64, 32)       160         ['permute[0][0]']                \n",
            "                                                                                                  \n",
            " tf.nn.gelu (TFOpLambda)        (None, 64, 32)       0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 64, 4)        132         ['tf.nn.gelu[0][0]']             \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 64, 4)        0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " permute_1 (Permute)            (None, 4, 64)        0           ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 4, 64)        0           ['conv1d[0][0]',                 \n",
            "                                                                  'permute_1[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_1 (LayerNo  (None, 4, 64)       128         ['add[0][0]']                    \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 4, 64)        4160        ['layer_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.gelu_1 (TFOpLambda)      (None, 4, 64)        0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 4, 64)        4160        ['tf.nn.gelu_1[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 4, 64)        0           ['dense_3[0][0]']                \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 4, 64)        0           ['dropout_1[0][0]',              \n",
            "                                                                  'add[0][0]']                    \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 4, 64)       128         ['add_1[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " permute_2 (Permute)            (None, 64, 4)        0           ['layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 64, 32)       160         ['permute_2[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.gelu_2 (TFOpLambda)      (None, 64, 32)       0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 64, 4)        132         ['tf.nn.gelu_2[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 64, 4)        0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " permute_3 (Permute)            (None, 4, 64)        0           ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 4, 64)        0           ['add_1[0][0]',                  \n",
            "                                                                  'permute_3[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 4, 64)       128         ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 4, 64)        4160        ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.gelu_3 (TFOpLambda)      (None, 4, 64)        0           ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 4, 64)        4160        ['tf.nn.gelu_3[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 4, 64)        0           ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 4, 64)        0           ['dropout_3[0][0]',              \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 4, 64)       128         ['add_3[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " permute_4 (Permute)            (None, 64, 4)        0           ['layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 64, 32)       160         ['permute_4[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.gelu_4 (TFOpLambda)      (None, 64, 32)       0           ['dense_8[0][0]']                \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 64, 4)        132         ['tf.nn.gelu_4[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 64, 4)        0           ['dense_9[0][0]']                \n",
            "                                                                                                  \n",
            " permute_5 (Permute)            (None, 4, 64)        0           ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 4, 64)        0           ['add_3[0][0]',                  \n",
            "                                                                  'permute_5[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 4, 64)       128         ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 4, 64)        4160        ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.gelu_5 (TFOpLambda)      (None, 4, 64)        0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 4, 64)        4160        ['tf.nn.gelu_5[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 4, 64)        0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 4, 64)        0           ['dropout_5[0][0]',              \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 4, 64)       128         ['add_5[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " permute_6 (Permute)            (None, 64, 4)        0           ['layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 64, 32)       160         ['permute_6[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.gelu_6 (TFOpLambda)      (None, 64, 32)       0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 64, 4)        132         ['tf.nn.gelu_6[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 64, 4)        0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " permute_7 (Permute)            (None, 4, 64)        0           ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 4, 64)        0           ['add_5[0][0]',                  \n",
            "                                                                  'permute_7[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 4, 64)       128         ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 4, 64)        4160        ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.gelu_7 (TFOpLambda)      (None, 4, 64)        0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 4, 64)        4160        ['tf.nn.gelu_7[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 4, 64)        0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 4, 64)        0           ['dropout_7[0][0]',              \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 4, 64)       128         ['add_7[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " permute_8 (Permute)            (None, 64, 4)        0           ['layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 64, 32)       160         ['permute_8[0][0]']              \n",
            "                                                                                                  \n",
            " tf.nn.gelu_8 (TFOpLambda)      (None, 64, 32)       0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 64, 4)        132         ['tf.nn.gelu_8[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 64, 4)        0           ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " permute_9 (Permute)            (None, 4, 64)        0           ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 4, 64)        0           ['add_7[0][0]',                  \n",
            "                                                                  'permute_9[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 4, 64)       128         ['add_8[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 4, 64)        4160        ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " tf.nn.gelu_9 (TFOpLambda)      (None, 4, 64)        0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 4, 64)        4160        ['tf.nn.gelu_9[0][0]']           \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 4, 64)        0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 4, 64)        0           ['dropout_9[0][0]',              \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 4, 64)       128         ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " permute_10 (Permute)           (None, 64, 4)        0           ['layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 64, 32)       160         ['permute_10[0][0]']             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_10 (TFOpLambda)     (None, 64, 32)       0           ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 64, 4)        132         ['tf.nn.gelu_10[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 64, 4)        0           ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " permute_11 (Permute)           (None, 4, 64)        0           ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 4, 64)        0           ['add_9[0][0]',                  \n",
            "                                                                  'permute_11[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 4, 64)       128         ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 4, 64)        4160        ['layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.gelu_11 (TFOpLambda)     (None, 4, 64)        0           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 4, 64)        4160        ['tf.nn.gelu_11[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 4, 64)        0           ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 4, 64)        0           ['dropout_11[0][0]',             \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 4, 64)       128         ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " permute_12 (Permute)           (None, 64, 4)        0           ['layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 64, 32)       160         ['permute_12[0][0]']             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_12 (TFOpLambda)     (None, 64, 32)       0           ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 64, 4)        132         ['tf.nn.gelu_12[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 64, 4)        0           ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            " permute_13 (Permute)           (None, 4, 64)        0           ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 4, 64)        0           ['add_11[0][0]',                 \n",
            "                                                                  'permute_13[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 4, 64)       128         ['add_12[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 4, 64)        4160        ['layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.gelu_13 (TFOpLambda)     (None, 4, 64)        0           ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 4, 64)        4160        ['tf.nn.gelu_13[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 4, 64)        0           ['dense_27[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 4, 64)        0           ['dropout_13[0][0]',             \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 4, 64)       128         ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " permute_14 (Permute)           (None, 64, 4)        0           ['layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " dense_28 (Dense)               (None, 64, 32)       160         ['permute_14[0][0]']             \n",
            "                                                                                                  \n",
            " tf.nn.gelu_14 (TFOpLambda)     (None, 64, 32)       0           ['dense_28[0][0]']               \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 64, 4)        132         ['tf.nn.gelu_14[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 64, 4)        0           ['dense_29[0][0]']               \n",
            "                                                                                                  \n",
            " permute_15 (Permute)           (None, 4, 64)        0           ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 4, 64)        0           ['add_13[0][0]',                 \n",
            "                                                                  'permute_15[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 4, 64)       128         ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 4, 64)        4160        ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.gelu_15 (TFOpLambda)     (None, 4, 64)        0           ['dense_30[0][0]']               \n",
            "                                                                                                  \n",
            " dense_31 (Dense)               (None, 4, 64)        4160        ['tf.nn.gelu_15[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 4, 64)        0           ['dense_31[0][0]']               \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 4, 64)        0           ['dropout_15[0][0]',             \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 4, 64)       128         ['add_15[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling1d (Glob  (None, 64)          0           ['layer_normalization_16[0][0]'] \n",
            " alAveragePooling1D)                                                                              \n",
            "                                                                                                  \n",
            " dense_32 (Dense)               (None, 2)            130         ['global_average_pooling1d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,177,890\n",
            "Trainable params: 1,157,410\n",
            "Non-trainable params: 20,480\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size and epochs\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "\n",
        "# Compile the model and start the training\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy' ,\n",
        "    optimizer=tf.keras.optimizers.Adam( learning_rate ) ,\n",
        "    metrics=[ 'accuracy' ]\n",
        ")\n",
        "\n",
        "model.fit(train_x ,\n",
        "          train_y ,\n",
        "          batch_size=batch_size ,\n",
        "          validation_data=( test_x , test_y ) ,\n",
        "          epochs=num_epochs ,\n",
        "          class_weight=class_weights ,\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF-wvlMSS1nz",
        "outputId": "e0f20bc1-064e-459e-be53-60c4b480862e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "191/191 [==============================] - 29s 58ms/step - loss: 0.6985 - accuracy: 0.5445 - val_loss: 0.5345 - val_accuracy: 0.7492\n",
            "Epoch 2/5\n",
            "191/191 [==============================] - 10s 51ms/step - loss: 0.4008 - accuracy: 0.8351 - val_loss: 0.5669 - val_accuracy: 0.7610\n",
            "Epoch 3/5\n",
            "191/191 [==============================] - 10s 54ms/step - loss: 0.1244 - accuracy: 0.9629 - val_loss: 0.8739 - val_accuracy: 0.7466\n",
            "Epoch 4/5\n",
            "191/191 [==============================] - 10s 54ms/step - loss: 0.0734 - accuracy: 0.9759 - val_loss: 0.9558 - val_accuracy: 0.7695\n",
            "Epoch 5/5\n",
            "191/191 [==============================] - 10s 54ms/step - loss: 0.0530 - accuracy: 0.9790 - val_loss: 0.9343 - val_accuracy: 0.7485\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7eb75ee15360>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch model predictions for test_x\n",
        "pred_y = model.predict( test_x )\n",
        "\n",
        "# Print the classification report\n",
        "report = sklearn.metrics.classification_report( np.argmax( test_y , axis=1 ) , np.argmax( pred_y , axis=1 ) , target_names=[ 'not disaster' , 'disaster' ] )\n",
        "print( report )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7mMtPkAS4lz",
        "outputId": "c3eb2142-0673-431d-9af2-d84e3de82a1d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48/48 [==============================] - 2s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "not disaster       0.80      0.73      0.77       857\n",
            "    disaster       0.69      0.77      0.73       666\n",
            "\n",
            "    accuracy                           0.75      1523\n",
            "   macro avg       0.75      0.75      0.75      1523\n",
            "weighted avg       0.75      0.75      0.75      1523\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix\n",
        "conf_matrix = sklearn.metrics.confusion_matrix( np.argmax( test_y , axis=1 ) ,np.argmax( pred_y , axis=1 ) )\n",
        "disp = sklearn.metrics.ConfusionMatrixDisplay( conf_matrix , display_labels=[ 'not disaster' , 'disaster' ] )\n",
        "disp.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "pJOTOUJES56r",
        "outputId": "8462a32d-36f9-4bdd-c16c-5872d579e986"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7eb75ee5fa30>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the test.csv file\n",
        "test_df = pd.read_csv('https://raw.githubusercontent.com/nikjohn7/Disaster-Tweets-Kaggle/main/data/test.csv', usecols=[ 'text' , 'id'])\n",
        "# Clean, tokenize, pad the sentences from test_df\n",
        "test_inputs = []\n",
        "for text in test_df[ 'text' ].values:\n",
        "    tokens = process_sent( text )\n",
        "    out = sent_to_int_seq( tokens )\n",
        "    out = pad_sequence( out , maxlen )\n",
        "    test_inputs.append( out )\n",
        "\n",
        "# Fetch predictions for test_inputs\n",
        "test_inputs = np.array( test_inputs )\n",
        "predicted_labels = np.argmax( model.predict( test_inputs ) , axis=1 )\n",
        "\n",
        "ids = test_df[ 'id' ].values\n",
        "\n",
        "# Create the output.csv file from ids and predicted_labels\n",
        "output_csv = { 'id' : ids , 'target' : predicted_labels }\n",
        "output_csv = pd.DataFrame.from_dict(output_csv)\n",
        "output_csv.to_csv('output.csv', index=False )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niqp1ZQFUZhk",
        "outputId": "493c74cb-c3f8-4f4c-fff4-d98d26027b5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "102/102 [==============================] - 1s 11ms/step\n"
          ]
        }
      ]
    }
  ]
}