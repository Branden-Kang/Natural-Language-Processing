{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN01tf0I+RIe/xHvfJi40Dl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@ogbodoebuka2/twitter-sentiment-analysis-what-are-people-saying-about-the-ukrainerussianwar-30f200f9768d)"
      ],
      "metadata": {
        "id": "3fo97EgfAT7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Various Libraries\n"
      ],
      "metadata": {
        "id": "rGJJZ3HTAXvA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2A3o3yKs_RQE"
      },
      "outputs": [],
      "source": [
        "#Install Libraries\n",
        "!pip install textblob\n",
        "!pip install tweepy\n",
        "!pip install pycountry\n",
        "!pip install langdetect\n",
        "!pip install twython\n",
        "from textblob import TextBlob\n",
        "import sys\n",
        "import tweepy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "!pip install pycountry\n",
        "import re\n",
        "import string\n",
        "import wordcloud\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "from PIL import Image\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from langdetect import detect\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a Twitter Developer Account\n"
      ],
      "metadata": {
        "id": "_8hUYEeFAYut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Authentication\n",
        "api_key = \"INPUT YOUR CONSUMER KEY\"\n",
        "api_secret = \"INPUT YOUR SECRET CONSUMER KEY\"\n",
        "access_token = \"INPUT YOUR ACCESS TOKEN\"\n",
        "access_token_secret = \"INPUT YOUR ACCESS TOKEN SECRET\"\n",
        "\n",
        "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"
      ],
      "metadata": {
        "id": "_JtIDGGsAWVT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis\n",
        "def percentage(part,whole):\n",
        " return 100 * float(part)/float(whole)\n",
        "keyword = input(\"Please enter keyword or hashtag to search: \")\n",
        "no_of_tweet = int(input (\"Please enter how many tweets to analyze: \"))\n",
        "tweets = tweepy.Cursor(api.search, q=keyword).items(no_of_tweet)\n",
        "positive = 0\n",
        "negative = 0\n",
        "neutral = 0\n",
        "polarity = 0\n",
        "tweet_list = []\n",
        "neutral_list = []\n",
        "negative_list = []\n",
        "positive_list = []"
      ],
      "metadata": {
        "id": "xX_M0X80Ab6-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifying our tweets into Positive, Negative and Neutral\n"
      ],
      "metadata": {
        "id": "Gtgz7sGEAeuG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in tweets:\n",
        "    #print(tweet.text)\n",
        "    tweet_list.append(tweet.text)\n",
        "    analysis = TextBlob(tweet.text)\n",
        "    score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)\n",
        "    neg = score[\"neg\"]\n",
        "    neu = score[\"neu\"]\n",
        "    pos = score[\"pos\"]\n",
        "    comp = score[\"compound\"]\n",
        "    polarity += analysis.sentiment.polarity\n",
        " \n",
        "    if neg > pos:\n",
        "        negative_list.append(tweet.text)\n",
        "        negative += 1\n",
        "    elif pos > neg:\n",
        "        positive_list.append(tweet.text)\n",
        "        positive += 1\n",
        "    elif pos == neg:\n",
        "        neutral_list.append(tweet.text)\n",
        "        neutral += 1\n",
        "\n",
        "positive = percentage(positive, no_of_tweet)\n",
        "negative = percentage(negative, no_of_tweet)\n",
        "neutral = percentage(neutral, no_of_tweet)\n",
        "polarity = percentage(polarity, no_of_tweet)\n",
        "positive = format(positive, \".1f\")\n",
        "negative = format(negative, \".1f\")\n",
        "neutral = format(neutral, \".1f\")\n",
        "#Number of Tweets (Total, Positive, Negative, Neutral)\n",
        "tweet_list = pd.DataFrame(tweet_list)\n",
        "neutral_list = pd.DataFraame(neutral_list)\n",
        "negative_list = pd.DataFrame(negative_list)\n",
        "positive_list = pd.DataFrame(positive_list)\n",
        "print(\"total number: \",len(tweet_list))\n",
        "print(\"positive number: \",len(positive_list))\n",
        "print(\"negative number: \", len(negative_list))\n",
        "print(\"neutral number: \",len(neutral_list))"
      ],
      "metadata": {
        "id": "kE9zFJHkAgga"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating PieCart\n",
        "labels = ['Positive ['+str(positive)+'%]' , 'Neutral ['+str(neutral)+'%]','Negative ['+str(negative)+'%]']\n",
        "sizes = [positive, neutral, negative]\n",
        "colors = [\"#81F495\",\"#A9E4EF\",\"#FF3C38\"]\n",
        "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
        "plt.style.use('default')\n",
        "plt.legend(labels)\n",
        "plt.title(\"Sentiment Analysis Result:  #\"+keyword+\"\" )\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kHTyLSMVAhp7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tidying Up Our Data\n"
      ],
      "metadata": {
        "id": "wyUh0MhJAims"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_list.drop_duplicates(inplace = True)\n",
        "tw_list = pd.DataFrame(tweet_list)\n",
        "tw_list[\"text\"] = tw_list[0]\n",
        "tw_list\n",
        "#Creating new dataframe and new features\n",
        "tw_list = pd.DataFrame(tweet_list)\n",
        "tw_list[\"text\"] = tw_list[0]\n",
        "\n",
        "#Removing RT, Punctuation etc\n",
        "remove_rt = lambda x: re.sub('RT @\\w+: ',\" \",x)\n",
        "rt = lambda x: re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",x)\n",
        "tw_list[\"text\"] = tw_list.text.map(remove_rt).map(rt)\n",
        "tw_list[\"text\"] = tw_list.text.str.lower()\n",
        "tw_list.head(15)"
      ],
      "metadata": {
        "id": "2F24jSfNAiZl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating Negative, Positive, Neutral and Compound values\n",
        "tw_list[['polarity', 'subjectivity']] = tw_list['text'].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))\n",
        "for index, row in tw_list['text'].iteritems():\n",
        "    score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
        "    neg = score['neg']\n",
        "    neu = score['neu']\n",
        "    pos = score['pos']\n",
        "    comp = score['compound']\n",
        "    if neg > pos:\n",
        "        tw_list.loc[index, 'sentiment'] = \"negative\"\n",
        "    elif pos > neg:\n",
        "        tw_list.loc[index, 'sentiment'] = \"positive\"\n",
        "    else:\n",
        "        tw_list.loc[index, 'sentiment'] = \"neutral\"\n",
        "    tw_list.loc[index, 'neg'] = neg\n",
        "    tw_list.loc[index, 'neu'] = neu\n",
        "    tw_list.loc[index, 'pos'] = pos\n",
        "    tw_list.loc[index, 'compound'] = comp\n",
        "\n",
        "tw_list.head(10)"
      ],
      "metadata": {
        "id": "KYHQrfqtAmWO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating new data frames for all sentiments (positive, negative and neutral)\n",
        "tw_list_negative = tw_list[tw_list[\"sentiment\"]==\"negative\"]\n",
        "tw_list_positive = tw_list[tw_list[\"sentiment\"]==\"positive\"]\n",
        "tw_list_neutral = tw_list[tw_list[\"sentiment\"]==\"neutral\"]\n",
        "#Function for count_values_in single columns\n",
        "def count_values_in_column(data,feature):\n",
        "    total=data.loc[:,feature].value_counts(dropna=False)\n",
        "    percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)\n",
        "    return pd.concat([total,percentage],axis=1,keys=['Total','Percentage'])\n",
        "#Count_values for sentiment\n",
        "pc = count_values_in_column(tw_list,\"sentiment\")\n",
        "pc"
      ],
      "metadata": {
        "id": "WH4ikAI9AnfB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data for Pie Chart\n",
        "piechart = count_values_in_column(tw_list,\"sentiment\")\n",
        "names= pc.index\n",
        "size=pc[\"Percentage\"]\n",
        " \n",
        "# Create a circle for the center of the plot\n",
        "my_circle=plt.Circle( (0,0), 0.7, color='white')\n",
        "plt.pie(size, labels=names, colors = [\"#A9E4EF\",\"#FF3C38\",\"#81F495\"])\n",
        "p=plt.gcf()\n",
        "p.gca().add_artist(my_circle)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fc7EWU8TAozN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to Create Wordcloud\n",
        "def create_wordcloud(text):\n",
        "    mask = np.array(Image.open(\"/Twitter.png\"))\n",
        "    stopwords = set(STOPWORDS)\n",
        "    wc = WordCloud(background_color=\"white\",\n",
        "                  mask = mask,\n",
        "                  max_words=5000,\n",
        "                  stopwords=stopwords,\n",
        "                  repeat=True)\n",
        "    wc.generate(str(text))\n",
        "    wc.to_file(\"wc.png\")\n",
        "    print(\"Word Cloud Saved Successfully\")\n",
        "    path=\"wc.png\"\n",
        "    display(Image.open(path))\n",
        "#Creating wordcloud for all tweets\n",
        "create_wordcloud(tw_list[\"text\"].values)"
      ],
      "metadata": {
        "id": "hO4SXHV_AqFA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordcloud for All Sentiments\n"
      ],
      "metadata": {
        "id": "s6hc8YZCArAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_wordcloud(text):\n",
        "    mask = np.array(Image.open(\"/cloud.png\"))\n",
        "    stopwords = set(STOPWORDS)\n",
        "    wc = WordCloud(background_color=\"white\",\n",
        "                  mask = mask,\n",
        "                  max_words=5000,\n",
        "                  stopwords=stopwords,\n",
        "                  repeat=True)\n",
        "    wc.generate(str(text))\n",
        "    wc.to_file(\"wc.png\")\n",
        "    print(\"Word Cloud Saved Successfully\")\n",
        "    path=\"wc.png\"\n",
        "    display(Image.open(path))\n",
        "#Creating wordcloud for all tweets\n",
        "create_wordcloud(tw_list[\"text\"].values)"
      ],
      "metadata": {
        "id": "oZtsJjV4AsXa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordcloud for Positive Sentiments\n"
      ],
      "metadata": {
        "id": "SydkVSNNAtcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating wordcloud for positive sentiment\n",
        "create_wordcloud(tw_list_positive[\"text\"].values)"
      ],
      "metadata": {
        "id": "B_VAFd25AuTd"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordcloud for Negative Sentiments\n"
      ],
      "metadata": {
        "id": "w1Y7-IaeAvP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating wordcloud for negative sentiment\n",
        "create_wordcloud(tw_list_negative[\"text\"].values)"
      ],
      "metadata": {
        "id": "TDqmR5VqAwDz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordcloud for Neutral Sentiments\n"
      ],
      "metadata": {
        "id": "wAYVwuaBAw4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating wordcloud for neutral sentiment\n",
        "create_wordcloud(tw_list_neutral[\"text\"].values)"
      ],
      "metadata": {
        "id": "b687ac6eAxwI"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}