{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/amazon-fine-food-reviews/hashes.txt\n/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n/kaggle/input/amazon-fine-food-reviews/database.sqlite\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Thanks to [Reference](https://towardsdatascience.com/latent-semantic-analysis-sentiment-classification-with-python-5f657346f6a3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.feature_selection import chi2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/amazon-fine-food-reviews/Reviews.csv')\ndf.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# TF-IDF"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer()\ntfidf.fit(df['Text'])","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"TfidfVectorizer()"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tfidf.transform(df['Text'])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Text'][2]","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"'This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis\\' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print([X[2, tfidf.vocabulary_['wardrobe']]])","execution_count":7,"outputs":[{"output_type":"stream","text":"[0.1981808502781283]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print([X[2, tfidf.vocabulary_['chewy']]])","execution_count":8,"outputs":[{"output_type":"stream","text":"[0.0977253475996827]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print([X[2, tfidf.vocabulary_['story']]])","execution_count":9,"outputs":[{"output_type":"stream","text":"[0.1269054955181263]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Let's do Sentiment Classification!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(inplace=True)\ndf[df['Score'] != 3]\ndf['Positivity'] = np.where(df['Score'] > 3, 1, 0)\ncols = ['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Score', 'Time', 'Summary']\ndf.drop(cols, axis=1, inplace=True)\ndf.head()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                                Text  Positivity\n0  I have bought several of the Vitality canned d...           1\n1  Product arrived labeled as Jumbo Salted Peanut...           0\n2  This is a confection that has been around a fe...           1\n3  If you are looking for the secret ingredient i...           0\n4  Great taffy at a great price.  There was a wid...           1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Positivity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I have bought several of the Vitality canned d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>This is a confection that has been around a fe...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>If you are looking for the secret ingredient i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Great taffy at a great price.  There was a wid...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Split the dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df.Text\ny = df.Positivity\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\nprint(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(X_train),\n                                                                             (len(X_train[y_train == 0]) / (len(X_train)*1.))*100,\n                                                                            (len(X_train[y_train == 1]) / (len(X_train)*1.))*100))","execution_count":11,"outputs":[{"output_type":"stream","text":"Train set has total 426308 entries with 21.91% negative, 78.09% positive\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def accuracy_summary(pipeline, X_train, y_train, X_test, y_test):\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    y_pred = sentiment_fit.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    print(\"accuracy score: {0:.2f}%\".format(accuracy*100))\n    return accuracy","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer()\nrf = RandomForestClassifier(class_weight=\"balanced\")\nn_features = np.arange(10000,20001,10000)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nfeature_accuracy_checker(vectorizer=cv, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=rf):\n    result = []\n    print(classifier)\n    print(\"\\n\")\n    for n in n_features:\n        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n        checker_pipeline = Pipeline([\n            ('vectorizer', vectorizer),\n            ('classifier', classifier)\n        ])\n        print(\"Test result for {} features\".format(n))\n        nfeature_accuracy = accuracy_summary(checker_pipeline, X_train, y_train, X_test, y_test)\n        result.append((n,nfeature_accuracy))\n    return result","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer()\nprint(\"Result for trigram with stop words (Tfidf)\\n\")\nfeature_result_tgt = nfeature_accuracy_checker(vectorizer=tfidf,ngram_range=(1, 3))","execution_count":15,"outputs":[{"output_type":"stream","text":"Result for trigram with stop words (Tfidf)\n\nRandomForestClassifier(class_weight='balanced')\n\n\nTest result for 10000 features\naccuracy score: 91.65%\nTest result for 20000 features\naccuracy score: 91.67%\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer(max_features=30000,ngram_range=(1, 3))\npipeline = Pipeline([\n        ('vectorizer', cv),\n        ('classifier', rf)\n    ])\nsentiment_fit = pipeline.fit(X_train, y_train)\ny_pred = sentiment_fit.predict(X_test)\nprint(classification_report(y_test, y_pred, target_names=['negative','positive']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Chi-Squared for Feature Selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=30000,ngram_range=(1, 3))\nX_tfidf = tfidf.fit_transform(df.Text)\ny = df.Positivity\nchi2score = chi2(X_tfidf, y)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nscores = list(zip(tfidf.get_feature_names(), chi2score))\nchi2 = sorted(scores, key=lambda x:x[1])\ntopchi2 = list(zip(*chi2[-20:]))\nx = range(len(topchi2[1]))\nlabels = topchi2[0]\nplt.barh(x,topchi2[1], align='center', alpha=0.5)\nplt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\nplt.yticks(x, labels)\nplt.xlabel('$\\chi^2$')\nplt.show();","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}